{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6dd55be",
   "metadata": {},
   "source": [
    "# Understanding the Kaggle Data\n",
    "The dataset acquired from [Kaggle](https://www.kaggle.com/code/martinkk5575/language-detection/data) contains words from several different languages. The noise contained in the dataset are duplicate words. To reduce this noise, the words will be broken down into single and double characters, then rated based on how often they show up in that respective language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94b50dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21995</th>\n",
       "      <td>hors du terrain les années  et  sont des année...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21996</th>\n",
       "      <td>ใน พศ  หลักจากที่เสด็จประพาสแหลมมลายู ชวา อินเ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21997</th>\n",
       "      <td>con motivo de la celebración del septuagésimoq...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21998</th>\n",
       "      <td>年月，當時還只有歲的她在美國出道，以mai-k名義推出首張英文《baby i like》，由...</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21999</th>\n",
       "      <td>aprilie sonda spațială messenger a nasa și-a ...</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  language\n",
       "0      klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
       "1      sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
       "2      ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
       "3      விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
       "4      de spons behoort tot het geslacht haliclona en...     Dutch\n",
       "...                                                  ...       ...\n",
       "21995  hors du terrain les années  et  sont des année...    French\n",
       "21996  ใน พศ  หลักจากที่เสด็จประพาสแหลมมลายู ชวา อินเ...      Thai\n",
       "21997  con motivo de la celebración del septuagésimoq...   Spanish\n",
       "21998  年月，當時還只有歲的她在美國出道，以mai-k名義推出首張英文《baby i like》，由...   Chinese\n",
       "21999   aprilie sonda spațială messenger a nasa și-a ...  Romanian\n",
       "\n",
       "[22000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import data*\n",
    "fileName = \"dataset.csv\"\n",
    "data = pd.read_csv(fileName)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18753df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=data['Text'] # Feature matrix\n",
    "y=data['language'] # Label\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the languages into a DataFrame that we aren't modifying\n",
    "languages = set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "017c263d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5207     สัมประสิทธิ์ฮอลล์ ฟิสิกส์ไฟฟ้า เกี่ยวกับสนามแม...\n",
       "4450     เกิดวันที่  พฤศจิกายน ภาคอะนิเมะ คดีฆาตกรรมบนจ...\n",
       "7033     i omgivningarna runt manigotagan river park re...\n",
       "487      நிஞ்சா ஹட்டோரி 忍者ハットリくん ninja hattori என்பது க...\n",
       "19537    эта страница деятельности м в ломоносова — ярк...\n",
       "                               ...                        \n",
       "11964    باباجان غفورف تاریخ‌دان و نویسندهٔ کتاب تاریخ ...\n",
       "21575    en  fue invitado por fernando ii para ocupar l...\n",
       "5390     doğu kanada atabasklarına geleneksel olarak dü...\n",
       "860      پژواک د يوې ځانگړې پروژې په توگه د اساسي قانون...\n",
       "15795    テンサイについては糖分を高度に精製する必要があることからサトウキビと同じような黒糖を作るのは...\n",
       "Name: Text, Length: 17600, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b99e5dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(dataframe, chars):\n",
    "    arr = dataframe.to_numpy()\n",
    "    new_arr = np.zeros((len(arr), len(chars)))\n",
    "    i=0\n",
    "    j=0\n",
    "    for text in arr:\n",
    "        sentence = text\n",
    "        count = 0\n",
    "        j=0\n",
    "        for char in chars:\n",
    "            \n",
    "            for letter in sentence:\n",
    "                if letter == char:\n",
    "                    count = count + 1\n",
    "                fraction = count/len(sentence)\n",
    "            new_arr[i,j] = fraction\n",
    "            j = j + 1\n",
    "        \n",
    "        i = i + 1\n",
    "            \n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "276f6714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_into_dataframe(array, chars):\n",
    "    data_frame = pd.DataFrame(array, columns = chars)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed5739d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5207     สัมประสิทธิ์ฮอลล์ ฟิสิกส์ไฟฟ้า เกี่ยวกับสนามแม...\n",
       "4450     เกิดวันที่  พฤศจิกายน ภาคอะนิเมะ คดีฆาตกรรมบนจ...\n",
       "7033     i omgivningarna runt manigotagan river park re...\n",
       "487      நிஞ்சா ஹட்டோரி 忍者ハットリくん ninja hattori என்பது க...\n",
       "19537    эта страница деятельности м в ломоносова — ярк...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panda = X_train.head()\n",
    "panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce97ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_22_features = ['e', 't', 'a', 'i', 'o', 'á', 'é', 'í']\n",
    "\n",
    "test_data = feature_engineering(panda, first_22_features)\n",
    "test_data_2 = numpy_into_dataframe(test_data, first_22_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfa4cb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e</th>\n",
       "      <th>t</th>\n",
       "      <th>a</th>\n",
       "      <th>i</th>\n",
       "      <th>o</th>\n",
       "      <th>á</th>\n",
       "      <th>é</th>\n",
       "      <th>í</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.106299</td>\n",
       "      <td>0.15748</td>\n",
       "      <td>0.244094</td>\n",
       "      <td>0.295276</td>\n",
       "      <td>0.318898</td>\n",
       "      <td>0.318898</td>\n",
       "      <td>0.318898</td>\n",
       "      <td>0.318898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00692</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>0.020761</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>0.024221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          e        t         a         i         o         á         é  \\\n",
       "0  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.106299  0.15748  0.244094  0.295276  0.318898  0.318898  0.318898   \n",
       "3  0.000000  0.00692  0.013841  0.020761  0.024221  0.024221  0.024221   \n",
       "4  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "          í  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.318898  \n",
       "3  0.024221  \n",
       "4  0.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15356f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----DEPRECATED AT THIS MOMENT IN TIME----#\n",
    "\n",
    "letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'] \n",
    "#put the most used letters here. These are sample letters for testing\n",
    "\n",
    "test = \"the quick brown fox jumps over the lazy dog\"\n",
    "#This is a test sentence. Replace this sentence with the testing data\n",
    "\n",
    "total = 0\n",
    "\n",
    "def counter(text, letters):\n",
    "    '''Analyzes words to calculate total letter count and the amount a letter is found in the data set. Data is returned in a list.\n",
    "    \n",
    "    Parameters:\n",
    "        text: a string of text. Can be single or multiple characters\n",
    "        letters: an array of characters to analyze the text with'''\n",
    "\n",
    "    \n",
    "    total = len(text)\n",
    "    print(text)\n",
    "    char_percentage = []\n",
    "    \n",
    "    #Remove spaces from total number of characters\n",
    "    for character in text:\n",
    "        \n",
    "        if character == \" \":\n",
    "            total = total - 1\n",
    "        \n",
    "    for letter in letters:\n",
    "        count = 0\n",
    "        for character in text:\n",
    "            #print(letter, character)\n",
    "            if letter == character:\n",
    "                count = count + 1\n",
    "                \n",
    "                #print(\"all\", letter, character, count, total)\n",
    "\n",
    "        char_percentage.append(count / total)\n",
    "        \n",
    "    \n",
    "    return char_percentage\n",
    "\n",
    "def formatCharPercentage(percentage_list, letters):\n",
    "    '''Returns a DataFrame with the percentage rate of letters repeating in a set of text'''\n",
    "\n",
    "    char_per_array = percentage_list\n",
    "    df = pd.DataFrame(char_per_array)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a0755636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the quick brown fox jumps over the lazy dog\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.114286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.028571\n",
       "1   0.028571\n",
       "2   0.028571\n",
       "3   0.028571\n",
       "4   0.085714\n",
       "5   0.028571\n",
       "6   0.028571\n",
       "7   0.057143\n",
       "8   0.028571\n",
       "9   0.028571\n",
       "10  0.028571\n",
       "11  0.028571\n",
       "12  0.028571\n",
       "13  0.028571\n",
       "14  0.114286\n",
       "15  0.028571\n",
       "16  0.028571\n",
       "17  0.057143\n",
       "18  0.028571\n",
       "19  0.057143\n",
       "20  0.057143\n",
       "21  0.028571\n",
       "22  0.028571\n",
       "23  0.028571\n",
       "24  0.028571\n",
       "25  0.028571"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array = counter(test, letters)\n",
    "\n",
    "test_frame = formatCharPercentage(test_array, letters)\n",
    "\n",
    "test_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67db2a28",
   "metadata": {},
   "source": [
    "## Creating Features: Most Used Characters\n",
    "To train the models to determine which language is being used by the user, we first need to know which characters are used in each language. The best approach for this is to used the dataset, _which is already using the characters from each language_, and find the **most used characters** in them.\n",
    "\n",
    "### Kaggle Resources\n",
    "----\n",
    "The following code is taken from the [Kaggle](https://www.kaggle.com/code/martinkk5575/language-detection/notebook) to understand how to process characters for each language. Kaggle uses the `CountVectorizor` Method from the `sklearn` module to tokenize the characters into readable 1's and 0's. Then, it counts how many times that character has been used in the sample data provided.\n",
    "\n",
    "This method reduces the necessity of locating alphabets for each language and creating custom functions to find the most used characters in the dataset.\n",
    " \n",
    "**To summarize Kaggle's findings: Languages based off the Latin Alphabet are easier to differentiate from each other in the data set while Languages with their own Alphabet, _like Chinese and Japanese_, can be differentiated by single characters alone.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3797753",
   "metadata": {},
   "source": [
    "This code here fits and transforms the X_train and X_test data sets into readable 1's and 0's and counts the number of times a specific character shows up in the datasets.The `min_df` parameter tells `CountVectorizor` to save any characters that are used **at least 1% of the time** in the dataset.\n",
    "\n",
    "These matrices are saved as `X_top1Percent_train_raw` and `X_top1Percent_test_raw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb378224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a list of single and double characters from the top 1% of to be used as features\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "top1PrecentMixtureVectorizer = CountVectorizer(analyzer='char', ngram_range=(1,2), min_df=1e-2)\n",
    "\n",
    "X_top1Percent_train_raw = top1PrecentMixtureVectorizer.fit_transform(X_train)\n",
    "X_top1Percent_test_raw = top1PrecentMixtureVectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b0c14",
   "metadata": {},
   "source": [
    "The `train_lang_dict()` function takes in the raw vectorized X_train and y_train data sets and converts them into readable dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a14148ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Command from Kaggle connects the character features to their specific language\n",
    "\n",
    "# Aggregate Unigrams per language\n",
    "def train_lang_dict(X_raw_counts, y_train):\n",
    "    lang_dict = {}\n",
    "    for i in range(len(y_train)):\n",
    "        lang = y_train[i]\n",
    "        v = np.array(X_raw_counts[i])\n",
    "        if not lang in lang_dict:\n",
    "            lang_dict[lang] = v\n",
    "        else:\n",
    "            lang_dict[lang] += v\n",
    "            \n",
    "    # to relative\n",
    "    for lang in lang_dict:\n",
    "        v = lang_dict[lang]\n",
    "        lang_dict[lang] = v / np.sum(v)\n",
    "        \n",
    "    return lang_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b62b41a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_dict_top1Percent = train_lang_dict(X_top1Percent_train_raw.toarray(), y_train.values)\n",
    "\n",
    "top1PercentFeatures = top1PrecentMixtureVectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf558dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thai</th>\n",
       "      <th>Swedish</th>\n",
       "      <th>Tamil</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Urdu</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>English</th>\n",
       "      <th>Persian</th>\n",
       "      <th>Pushto</th>\n",
       "      <th>...</th>\n",
       "      <th>Portugese</th>\n",
       "      <th>Turkish</th>\n",
       "      <th>Estonian</th>\n",
       "      <th>Hindi</th>\n",
       "      <th>Dutch</th>\n",
       "      <th>Latin</th>\n",
       "      <th>French</th>\n",
       "      <th>Korean</th>\n",
       "      <th>Indonesian</th>\n",
       "      <th>Japanese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027754</td>\n",
       "      <td>0.076811</td>\n",
       "      <td>0.058364</td>\n",
       "      <td>0.070887</td>\n",
       "      <td>0.108270</td>\n",
       "      <td>0.016015</td>\n",
       "      <td>0.083846</td>\n",
       "      <td>0.082739</td>\n",
       "      <td>0.096563</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083560</td>\n",
       "      <td>0.066449</td>\n",
       "      <td>0.063049</td>\n",
       "      <td>0.104208</td>\n",
       "      <td>0.078265</td>\n",
       "      <td>0.067217</td>\n",
       "      <td>0.081913</td>\n",
       "      <td>0.206226</td>\n",
       "      <td>0.069826</td>\n",
       "      <td>0.011205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>0.010499</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.005147</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3074</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3079 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Thai   Swedish     Tamil   Russian      Urdu   Chinese   Spanish  \\\n",
       "0     0.027754  0.076811  0.058364  0.070887  0.108270  0.016015  0.083846   \n",
       "1     0.000406  0.000100  0.000085  0.000019  0.000114  0.000137  0.000195   \n",
       "2     0.000195  0.000286  0.000220  0.000261  0.000049  0.000188  0.000137   \n",
       "3     0.000013  0.000006  0.000016  0.000016  0.000014  0.000000  0.000081   \n",
       "4     0.000230  0.003921  0.000140  0.000073  0.000212  0.000947  0.006234   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3074  0.000000  0.000000  0.000000  0.000000  0.000000  0.006177  0.000000   \n",
       "3075  0.000000  0.000000  0.000000  0.000000  0.000000  0.006169  0.000000   \n",
       "3076  0.000000  0.000000  0.000000  0.000000  0.000000  0.000785  0.000000   \n",
       "3077  0.000000  0.000000  0.000000  0.000000  0.000000  0.059402  0.000000   \n",
       "3078  0.000000  0.000000  0.000000  0.000000  0.000000  0.001997  0.000000   \n",
       "\n",
       "       English   Persian    Pushto  ...  Portugese   Turkish  Estonian  \\\n",
       "0     0.082739  0.096563  0.107686  ...   0.083560  0.066449  0.063049   \n",
       "1     0.000516  0.000013  0.000061  ...   0.000302  0.000366  0.000405   \n",
       "2     0.000167  0.000098  0.000458  ...   0.000177  0.000225  0.000113   \n",
       "3     0.000022  0.000009  0.000007  ...   0.000023  0.000009  0.000023   \n",
       "4     0.010499  0.000036  0.000606  ...   0.008497  0.005147  0.004500   \n",
       "...        ...       ...       ...  ...        ...       ...       ...   \n",
       "3074  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "3075  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "3076  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "3077  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "3078  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "\n",
       "         Hindi     Dutch     Latin    French    Korean  Indonesian  Japanese  \n",
       "0     0.104208  0.078265  0.067217  0.081913  0.206226    0.069826  0.011205  \n",
       "1     0.000183  0.000141  0.000227  0.000023  0.000740    0.000243  0.000079  \n",
       "2     0.000199  0.000884  0.000291  0.000285  0.000247    0.000144  0.000905  \n",
       "3     0.000022  0.000076  0.000099  0.000016  0.000038    0.000023  0.000000  \n",
       "4     0.000187  0.003532  0.008095  0.004858  0.000218    0.004301  0.000553  \n",
       "...        ...       ...       ...       ...       ...         ...       ...  \n",
       "3074  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000  0.006213  \n",
       "3075  0.000000  0.000000  0.000000  0.000000  0.000004    0.000000  0.006207  \n",
       "3076  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000  0.000668  \n",
       "3077  0.000000  0.000000  0.000000  0.000000  0.000209    0.000000  0.000024  \n",
       "3078  0.000000  0.000000  0.000000  0.000000  0.000029    0.000000  0.000273  \n",
       "\n",
       "[3079 rows x 22 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(language_dict_top1Percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f036f3",
   "metadata": {},
   "source": [
    "The `getRelevantGramsPerLanguage()` function processes the dictionary and returns a dictionary with only the top 50 **most used** characters for **each** language. This number _can_ be changed by setting `top=x` when you call `getRelevantGramsPerLanguage()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e18e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelevantGramsPerLanguage(features, language_dict, top=50):\n",
    "    relevantGramsPerLanguage = {}\n",
    "    for lang in languages:\n",
    "        chars = []\n",
    "        relevantGramsPerLanguage[lang] = chars\n",
    "        v = language_dict[lang]\n",
    "        sortIndex = (-v).argsort()[:top]\n",
    "        for i in range(len(sortIndex)):\n",
    "            chars.append(features[sortIndex[i]])\n",
    "    return relevantGramsPerLanguage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fae2d19",
   "metadata": {},
   "source": [
    "Below Displays the top 8 and 12 Characters from each language in a DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a571530d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Hindi</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Japanese</th>\n",
       "      <th>Estonian</th>\n",
       "      <th>Arabic</th>\n",
       "      <th>Indonesian</th>\n",
       "      <th>Urdu</th>\n",
       "      <th>Romanian</th>\n",
       "      <th>Tamil</th>\n",
       "      <th>...</th>\n",
       "      <th>Portugese</th>\n",
       "      <th>Thai</th>\n",
       "      <th>Korean</th>\n",
       "      <th>English</th>\n",
       "      <th>Dutch</th>\n",
       "      <th>French</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>Latin</th>\n",
       "      <th>Persian</th>\n",
       "      <th>Swedish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>の</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>்</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>า</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>，</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>ा</td>\n",
       "      <td>о</td>\n",
       "      <td>、</td>\n",
       "      <td>a</td>\n",
       "      <td>ا</td>\n",
       "      <td></td>\n",
       "      <td>ا</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>น</td>\n",
       "      <td>이</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>的</td>\n",
       "      <td>i</td>\n",
       "      <td>ا</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>क</td>\n",
       "      <td>и</td>\n",
       "      <td>に</td>\n",
       "      <td>i</td>\n",
       "      <td>ل</td>\n",
       "      <td>n</td>\n",
       "      <td>ی</td>\n",
       "      <td>a</td>\n",
       "      <td>க</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>ร</td>\n",
       "      <td>의</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>。</td>\n",
       "      <td>a</td>\n",
       "      <td>ی</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>o</td>\n",
       "      <td>र</td>\n",
       "      <td>е</td>\n",
       "      <td>た</td>\n",
       "      <td>e</td>\n",
       "      <td>ي</td>\n",
       "      <td>e</td>\n",
       "      <td>ر</td>\n",
       "      <td>i</td>\n",
       "      <td>ு</td>\n",
       "      <td>...</td>\n",
       "      <td>o</td>\n",
       "      <td></td>\n",
       "      <td>다</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td></td>\n",
       "      <td>e</td>\n",
       "      <td>ر</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>्</td>\n",
       "      <td>а</td>\n",
       "      <td>る</td>\n",
       "      <td>s</td>\n",
       "      <td>ال</td>\n",
       "      <td>i</td>\n",
       "      <td>و</td>\n",
       "      <td>r</td>\n",
       "      <td>ி</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>ก</td>\n",
       "      <td>의</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>年</td>\n",
       "      <td>t</td>\n",
       "      <td>د</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s</td>\n",
       "      <td>े</td>\n",
       "      <td>н</td>\n",
       "      <td>。</td>\n",
       "      <td>t</td>\n",
       "      <td>م</td>\n",
       "      <td>r</td>\n",
       "      <td>ک</td>\n",
       "      <td>n</td>\n",
       "      <td>த</td>\n",
       "      <td>...</td>\n",
       "      <td>i</td>\n",
       "      <td>อ</td>\n",
       "      <td>에</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>i</td>\n",
       "      <td>在</td>\n",
       "      <td>s</td>\n",
       "      <td>ن</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>r</td>\n",
       "      <td>ि</td>\n",
       "      <td>с</td>\n",
       "      <td>は</td>\n",
       "      <td>l</td>\n",
       "      <td>و</td>\n",
       "      <td>u</td>\n",
       "      <td>م</td>\n",
       "      <td>t</td>\n",
       "      <td>்</td>\n",
       "      <td>...</td>\n",
       "      <td>r</td>\n",
       "      <td>่</td>\n",
       "      <td>는</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>、</td>\n",
       "      <td>n</td>\n",
       "      <td>ه</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i</td>\n",
       "      <td>स</td>\n",
       "      <td>р</td>\n",
       "      <td>と</td>\n",
       "      <td>n</td>\n",
       "      <td>ا</td>\n",
       "      <td>t</td>\n",
       "      <td>ن</td>\n",
       "      <td>u</td>\n",
       "      <td>ப</td>\n",
       "      <td>...</td>\n",
       "      <td>d</td>\n",
       "      <td>เ</td>\n",
       "      <td>는</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>t</td>\n",
       "      <td>一</td>\n",
       "      <td>r</td>\n",
       "      <td>و</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Spanish Hindi Russian Japanese Estonian Arabic Indonesian Urdu Romanian  \\\n",
       "0                              の                          a                 \n",
       "1       e     ा       о        、        a      ا               ا        e   \n",
       "2       a     क       и        に        i      ل          n    ی        a   \n",
       "3       o     र       е        た        e      ي          e    ر        i   \n",
       "4       n     ्       а        る        s     ال          i    و        r   \n",
       "5       s     े       н        。        t      م          r    ک        n   \n",
       "6       r     ि       с        は        l      و          u    م        t   \n",
       "7       i     स       р        と        n      ا          t    ن        u   \n",
       "\n",
       "  Tamil  ... Portugese Thai Korean English Dutch French Chinese Latin Persian  \\\n",
       "0     ்  ...              า                                   ，                 \n",
       "1        ...         a    น      이       e     e      e       的     i       ا   \n",
       "2     க  ...         e    ร      의       a     n      a       。     a       ی   \n",
       "3     ு  ...         o           다       t     a      n             e       ر   \n",
       "4     ி  ...         s    ก     의        i     i      s       年     t       د   \n",
       "5     த  ...         i    อ      에       o     r      i       在     s       ن   \n",
       "6    ்   ...         r    ่      는       n     t      r       、     n       ه   \n",
       "7     ப  ...         d    เ     는        s     o      t       一     r       و   \n",
       "\n",
       "  Swedish  \n",
       "0          \n",
       "1       e  \n",
       "2       r  \n",
       "3       a  \n",
       "4       n  \n",
       "5       t  \n",
       "6       i  \n",
       "7       s  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top8PerLanguage_dict = getRelevantGramsPerLanguage(top1PercentFeatures, language_dict_top1Percent, top=8)\n",
    "pd.DataFrame(top8PerLanguage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01d01a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Hindi</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Japanese</th>\n",
       "      <th>Estonian</th>\n",
       "      <th>Arabic</th>\n",
       "      <th>Indonesian</th>\n",
       "      <th>Urdu</th>\n",
       "      <th>Romanian</th>\n",
       "      <th>Tamil</th>\n",
       "      <th>...</th>\n",
       "      <th>Portugese</th>\n",
       "      <th>Thai</th>\n",
       "      <th>Korean</th>\n",
       "      <th>English</th>\n",
       "      <th>Dutch</th>\n",
       "      <th>French</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>Latin</th>\n",
       "      <th>Persian</th>\n",
       "      <th>Swedish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>の</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>்</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>า</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>，</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>ा</td>\n",
       "      <td>о</td>\n",
       "      <td>、</td>\n",
       "      <td>a</td>\n",
       "      <td>ا</td>\n",
       "      <td></td>\n",
       "      <td>ا</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>น</td>\n",
       "      <td>이</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>的</td>\n",
       "      <td>i</td>\n",
       "      <td>ا</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>क</td>\n",
       "      <td>и</td>\n",
       "      <td>に</td>\n",
       "      <td>i</td>\n",
       "      <td>ل</td>\n",
       "      <td>n</td>\n",
       "      <td>ی</td>\n",
       "      <td>a</td>\n",
       "      <td>க</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>ร</td>\n",
       "      <td>의</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>。</td>\n",
       "      <td>a</td>\n",
       "      <td>ی</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>o</td>\n",
       "      <td>र</td>\n",
       "      <td>е</td>\n",
       "      <td>た</td>\n",
       "      <td>e</td>\n",
       "      <td>ي</td>\n",
       "      <td>e</td>\n",
       "      <td>ر</td>\n",
       "      <td>i</td>\n",
       "      <td>ு</td>\n",
       "      <td>...</td>\n",
       "      <td>o</td>\n",
       "      <td></td>\n",
       "      <td>다</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td></td>\n",
       "      <td>e</td>\n",
       "      <td>ر</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>्</td>\n",
       "      <td>а</td>\n",
       "      <td>る</td>\n",
       "      <td>s</td>\n",
       "      <td>ال</td>\n",
       "      <td>i</td>\n",
       "      <td>و</td>\n",
       "      <td>r</td>\n",
       "      <td>ி</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>ก</td>\n",
       "      <td>의</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>年</td>\n",
       "      <td>t</td>\n",
       "      <td>د</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s</td>\n",
       "      <td>े</td>\n",
       "      <td>н</td>\n",
       "      <td>。</td>\n",
       "      <td>t</td>\n",
       "      <td>م</td>\n",
       "      <td>r</td>\n",
       "      <td>ک</td>\n",
       "      <td>n</td>\n",
       "      <td>த</td>\n",
       "      <td>...</td>\n",
       "      <td>i</td>\n",
       "      <td>อ</td>\n",
       "      <td>에</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>i</td>\n",
       "      <td>在</td>\n",
       "      <td>s</td>\n",
       "      <td>ن</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>r</td>\n",
       "      <td>ि</td>\n",
       "      <td>с</td>\n",
       "      <td>は</td>\n",
       "      <td>l</td>\n",
       "      <td>و</td>\n",
       "      <td>u</td>\n",
       "      <td>م</td>\n",
       "      <td>t</td>\n",
       "      <td>்</td>\n",
       "      <td>...</td>\n",
       "      <td>r</td>\n",
       "      <td>่</td>\n",
       "      <td>는</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>、</td>\n",
       "      <td>n</td>\n",
       "      <td>ه</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i</td>\n",
       "      <td>स</td>\n",
       "      <td>р</td>\n",
       "      <td>と</td>\n",
       "      <td>n</td>\n",
       "      <td>ا</td>\n",
       "      <td>t</td>\n",
       "      <td>ن</td>\n",
       "      <td>u</td>\n",
       "      <td>ப</td>\n",
       "      <td>...</td>\n",
       "      <td>d</td>\n",
       "      <td>เ</td>\n",
       "      <td>는</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>t</td>\n",
       "      <td>一</td>\n",
       "      <td>r</td>\n",
       "      <td>و</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>l</td>\n",
       "      <td>क</td>\n",
       "      <td>т</td>\n",
       "      <td>ー</td>\n",
       "      <td>u</td>\n",
       "      <td>ن</td>\n",
       "      <td>s</td>\n",
       "      <td>ہ</td>\n",
       "      <td>l</td>\n",
       "      <td>ம</td>\n",
       "      <td>...</td>\n",
       "      <td>n</td>\n",
       "      <td>ง</td>\n",
       "      <td>하</td>\n",
       "      <td>r</td>\n",
       "      <td>d</td>\n",
       "      <td>l</td>\n",
       "      <td>中</td>\n",
       "      <td>u</td>\n",
       "      <td>م</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d</td>\n",
       "      <td>न</td>\n",
       "      <td>в</td>\n",
       "      <td>を</td>\n",
       "      <td>o</td>\n",
       "      <td>ت</td>\n",
       "      <td>an</td>\n",
       "      <td>ے</td>\n",
       "      <td>o</td>\n",
       "      <td>ட</td>\n",
       "      <td>...</td>\n",
       "      <td>t</td>\n",
       "      <td>ม</td>\n",
       "      <td>을</td>\n",
       "      <td>h</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "      <td>ت</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>t</td>\n",
       "      <td>त</td>\n",
       "      <td>л</td>\n",
       "      <td>し</td>\n",
       "      <td>k</td>\n",
       "      <td>ر</td>\n",
       "      <td>k</td>\n",
       "      <td>ل</td>\n",
       "      <td>c</td>\n",
       "      <td>ர</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>ั</td>\n",
       "      <td>을</td>\n",
       "      <td>l</td>\n",
       "      <td>n</td>\n",
       "      <td>u</td>\n",
       "      <td>e</td>\n",
       "      <td>m</td>\n",
       "      <td>ب</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c</td>\n",
       "      <td>ं</td>\n",
       "      <td>к</td>\n",
       "      <td>て</td>\n",
       "      <td>r</td>\n",
       "      <td>ب</td>\n",
       "      <td>d</td>\n",
       "      <td>ک</td>\n",
       "      <td>e</td>\n",
       "      <td>ா</td>\n",
       "      <td>...</td>\n",
       "      <td>o</td>\n",
       "      <td>ี</td>\n",
       "      <td>로</td>\n",
       "      <td>d</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>是</td>\n",
       "      <td>c</td>\n",
       "      <td>س</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Spanish Hindi Russian Japanese Estonian Arabic Indonesian Urdu Romanian  \\\n",
       "0                               の                          a                 \n",
       "1        e     ा       о        、        a      ا               ا        e   \n",
       "2        a     क       и        に        i      ل          n    ی        a   \n",
       "3        o     र       е        た        e      ي          e    ر        i   \n",
       "4        n     ्       а        る        s     ال          i    و        r   \n",
       "5        s     े       н        。        t      م          r    ک        n   \n",
       "6        r     ि       с        は        l      و          u    م        t   \n",
       "7        i     स       р        と        n      ا          t    ن        u   \n",
       "8        l     क       т        ー        u      ن          s    ہ        l   \n",
       "9        d     न       в        を        o      ت         an    ے        o   \n",
       "10       t     त       л        し        k      ر          k    ل        c   \n",
       "11       c     ं       к        て        r      ب          d    ک       e    \n",
       "\n",
       "   Tamil  ... Portugese Thai Korean English Dutch French Chinese Latin  \\\n",
       "0      ்  ...              า                                   ，         \n",
       "1         ...         a    น      이       e     e      e       的     i   \n",
       "2      க  ...         e    ร      의       a     n      a       。     a   \n",
       "3      ு  ...         o           다       t     a      n             e   \n",
       "4      ி  ...         s    ก     의        i     i      s       年     t   \n",
       "5      த  ...         i    อ      에       o     r      i       在     s   \n",
       "6     ்   ...         r    ่      는       n     t      r       、     n   \n",
       "7      ப  ...         d    เ     는        s     o      t       一     r   \n",
       "8      ம  ...         n    ง      하       r     d      l       中     u   \n",
       "9      ட  ...         t    ม      을       h     s     e        a     o   \n",
       "10     ர  ...         m    ั     을        l    n       u       e     m   \n",
       "11     ா  ...        o     ี      로       d     l      o       是     c   \n",
       "\n",
       "   Persian Swedish  \n",
       "0                   \n",
       "1        ا       e  \n",
       "2        ی       r  \n",
       "3        ر       a  \n",
       "4        د       n  \n",
       "5        ن       t  \n",
       "6        ه       i  \n",
       "7        و       s  \n",
       "8        م       d  \n",
       "9        ت       l  \n",
       "10       ب       o  \n",
       "11       س       m  \n",
       "\n",
       "[12 rows x 22 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top12PerLanguage_dict = getRelevantGramsPerLanguage(top1PercentFeatures, language_dict_top1Percent, top=12)\n",
    "pd.DataFrame(top12PerLanguage_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58581a6a",
   "metadata": {},
   "source": [
    "## Training the Model: RandomForests\n",
    "Now that we know the top 8 and 10 used characters for each language, we can use them to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f700401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b05f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create these arrays into dictonaries\n",
    "english_alpha = [a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z]\n",
    "estonian_alpha = [A, B, D, E, F, G, H, I, J, K, L, M, N, O, P, R, S, Š, Z, Ž, T, U, V, Õ, Ä, Ö, Ü]\n",
    "swedish_alpha = [a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z, å, ä, ö]\n",
    "thai_alpha = [ก, ข, ค, ฅ, ฆ, ง, จ, ฉ, ช, ฌ, ญ, ฎ, ฏ, ฐ, ฑ, ฒ, ณ, ด, ต, ถ, ท, ธ, น, บ, บ, ผ, ฝ, พ, ฟ, ภ, \n",
    "               ม, ย, ร, ล, ว, ศ, ษ, ส, ห, ฬ, อ, ฮ] \n",
    "tamil_alpha = [அ, ஆ, இ, ஈ, உ, ஊ, எ, ஏ, ஐ, ஒ, ஓ, ஔ, க, ங, ச, ஞ, ட, ண, த, ந, ன, ப, ம, ய, ர, ற, ல, ள, ழ, வ]\n",
    "dutch_alpha = english_alpha\n",
    "japanese_alpha = [ぁ, あ, ぃ, い, ぅ, う, ぇ, え, ぉ, お, か, が, き, ぎ, く, ぐ, け, げ, こ, ご, さ, ざ, し, じ, す, ず,\n",
    "                  せ, ぜ, そ, ぞ, た, だ, ち, ぢ, っ, つ, づ, て, で, と, ど, な, に, ぬ, ね, の, は, ば, ぱ, ひ, び, ぴ,\n",
    "                  ふ, ぶ, ぷ, へ, べ, れ, る, り, ら, よ, ょ, ゆ, ゅ, や, ゃ, も, め, む, み, ま, ぽ, ぼ, ほ, ぺ, ろ, ゎ,\n",
    "                  わ, ゐ, ゑ, を, ん, ゔ, ゕ, ゖ,  ゚, ゛, ゜, ゝ, ゞ, ゟ, ゠, ァ, ア, サ, ゴ, コ, ゲ, ケ, グ, ク, ギ, キ,\n",
    "                  ガ, カ, オ, ォ, エ, ェ, ウ, ゥ, イ, ィ, ザ, シ, ジ, ス, ズ, セ, ゼ, ソ, ゾ, タ ,ダ ,チ ,ヂ, ッ, ツ, ヅ,\n",
    "                  テ, デ, ト, ホ, ペ, ベ, ヘ, プ, ブ, フ, ピ, ビ, ヒ, パ, バ, ハ, ノ, ネ, ヌ, ニ, ナ, ド, ボ, ポ, マ, ミ, \n",
    "                  ム, メ, モ, ャ, ヤ, ュ, ユ, ョ, ヨ, ラ, リ, ル, レ, ロ, ヮ, ㍿, ㍐, ヿ, ヾ, ヽ, ー, ・, ヺ, ヹ, ヸ, ヷ,\n",
    "                  ヶ, ヵ, ヴ, ン, ヲ, ヱ, ヰ, ワ]\n",
    "turkish_alpha = [a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, r, s, t, u, v, y, z, ç, ğ, ı, İ, î, ö, ş, ü]\n",
    "latin_alpha = english_alpha\n",
    "urdu_alpha = [ش,س,ژ,ز,ڑ,ر,ذ,ڈ,د,خ,ح,چ,\n",
    "              ج,ث,ٹ,ت,پ,ب,آ,ا,ے,ی,ھ,ہ,و,ں,ن,م,ل,گ,ک,ق,ف,غ,ع,ظ,ط,ض,ص]\n",
    "indonesian_alpha = english_alpha\n",
    "portuguese_alpha = [ç, á, é, í, ó, ú, â, ê, ô, ã, õ, à, è, ì, ò, ù, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z]\n",
    "french_alpha = [ç, é, â, ê, î, ô, û, à, è, ì, ò, ù, ë, ï, ü, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z]\n",
    "chinese_alpha = [胡, 赛, 尼, 本, 人, 和, 小, 说, 的, 主, 人, 公, 阿, 米, 尔, 一, 样, 都, 是, 出, 生, 在, 阿, 富, 汗, 首, 都, \n",
    "                 喀, 布, 尔, 少, 年, 时, 代, 便, 离, 开, 了, 这, 个, 国, 家, 。, 胡, 赛, 尼, 直, 到, 年, 小, 说, 出, 版, 之, \n",
    "                 后, 才, 首, 次, 回, 到, 已, 经, 离, 开, 年, 的, 祖, 国, 。, 他, 在, 苏, 联, 入, 侵, 时, 离, 开, 了, 阿, 富, \n",
    "                 汗, 而, 他, 的, 很, 多, 童, 年, 好, 友, 在, 阿, 富, 汗, 生, 活, 在, 他, 们, 出, 发, 之, 前, 罗, 伯, 特, 伊,\n",
    "                 达, 尔, 文, 卷, 查, 尔, 斯, 赖, 尔, 所, 著, 地, 质, 学, 原, 理, 在, 南, 美, 他, 得, 到, 第, 卷, 该, 书, 将, \n",
    "                 地, 形, 地, 貌, 解, 释, 为, 漫, 长, 历, 史, 时, 间, 渐, 进, 演, 变, 的, 的, 结, 果, 当, 他, 旅, 程, 的, 第, \n",
    "                 站, 抵, 达, 圣, 地, 亚, 哥, 佛, 得, 角, 的, 时, 候, 达, 尔, 文]\n",
    "korean_alpha = [ᄁ,ᄂ,ᄃ,ᄄ,ᄅᄆᄇ,ᄈ,ᄉ,ᄊ,ᄋ,ᄌᄍ,ᄎ,ᄏ,ᄐ,ᄑᄒ,아,악,안,알,암,압,앙,앞애,액,앵야,얀,약,양,얘,어,억,\n",
    "                언,얼,엄,업,엉,에,여,역,연,열,염,엽,영,예,ᄀ,여,역,연,열,염,엽,영,예,오,옥,온,올,옴,옹,와,완,왈,왕,왜,외,왼,\n",
    "                요,욕,용,우,욱,운,울,움,웅,워,원,월,위,유,육,윤,율,융,윷,으,은,을,음읍,응,의,이,익,인,일,임,입,잉,잎]\n",
    "hindi_alpha = [ऄ, अ, आ, इ, ई, उ, ऊ, ऋ, ऌ, ऍ, ऎ, ए, ऐ, ऑ, ऒ, ओ, औ, क, ख, ग, घ, ङ, च, छ, ज, झ, प, ऩ, न, ध, द, \n",
    "               थ, त, ण, ढ, ड, ठ, ट, ञ, फ, ब, भ, म, य, र, ऱ, ल, ळ, ऴ, व, श, ष, ४, ३, २, १, ०, ॥, ।, ॡ, ॠ, ॐ, ऽ, \n",
    "               ह, स, ५, ६, ७, ॲ, ॳ, ॴ, ॵ, ॶ, ॷ, ॹ, ॺ, ॻ, ॼ, ॾ, ॿ, ೱऀँं, ः, ऺ, ऻ, ा, ि, ी, ॎ, ॏॕैेॣॢ, ॗ]\n",
    "spanish_alpha = [á, é, í, ó, ú, ñ, ü, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z]\n",
    "pushto_alpha = [,ﺏ ,پ ,ﺕ ,ټ ,ﺙ ,ﺝ ,چ ,ﺡ ,ﺥ ,څ ,ځ ,ﺩ ,ډ ,ﺫ ,ﺭ ,ړ ,ﺯ ,ژ ,ږ ,ﺱ ,ﺵ ,ښ ,ﺹ ,ﺽ ,ﻁ ,ﻅ ,ﻉ ,ﻍ ,ﻑ ,ﻕ ,ک ,ګ ,ﻝ ,ﻡ ,ﻥ ,ڼ, ,ﻭ ,ه ,ۀ ,ي ,ې ,ی ,ۍ ,ئ]\n",
    "persian_alpha = [,ش,س,ژ,ز,ر,ذ,د,خ,ح,چ,ج,ث,ت,پ,ب,آ,ا,ص,ض,ط,ظ,ع,غ,ف,ق,ک,گ,ل,م,ن,و,ه,ی]\n",
    "romanian_alpha = [ă, â, î, ș, ş, ț, ţ, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z]\n",
    "russian_alpha = [б, в, г, д, ж, з, к, л, м, н, п, р, с, т, ф, х, ц, ч, ш, щ, а, е, ё, и, о, у, ы, э, ю, я, й]\n",
    "arabic_alpha = [ش,س,ز,ر,ذ,د,خ,ح,ج,ث,ت,ب,ا,ء,ي,و,ه,ن,م,ل,ك,ق,ف,غ,ع,ظ,ط,ض,ص]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea6f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Average Word Length of a single string\n",
    "def avg_word_len(string):\n",
    "    # Split string up and find total amount of words present\n",
    "    words = string.split()\n",
    "    wordCount = len(words)\n",
    "    \n",
    "    # Calculate actual average  \n",
    "    ch = 0\n",
    "    for word in words:\n",
    "        ch += len(word) # Add up all chars\n",
    "    avg = ch / wordCount # Divide sum of chars by amount of words present\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6809f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the Average Sentence Length across a piece of text\n",
    "def avg_sent_len(text):\n",
    "  sentences = text.split(\".\") # Split the text into a list of sentences.\n",
    "  words = text.split(\" \") # split the input text into a list of separate words\n",
    "  if(sentences[len(sentences)-1]==\"\"): # if the last value in sentences is an empty string\n",
    "    average_sentence_length = len(words) / len(sentences)-1\n",
    "  else:\n",
    "    average_sentence_length = len(words) / len(sentences)\n",
    "  return average_sentence_length # returning avg length of sentence\n",
    "  \n",
    "ans = avg_sent_len(\"I am going.to see you later\") # function call\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd13fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets test this function (avg_sent_len)          #Mr., Dr., Ms., etc. are words that may be a problem for this function\n",
    "avg_sent_len(input(\"Provide a body of text: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e12b7e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Hot Encoding                                #Attempt failed lol\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder() # instantiate one hot encoder\n",
    "cat_encoder2 = cat_encoder.fit_transform(data_trans)\n",
    "cat_encoder2 #sparse matrix\n",
    "\n",
    "cat_encoder2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0836bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "features = pd.get_dummies(data_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c881dd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_ أ</th>\n",
       "      <th>1_ ہ</th>\n",
       "      <th>2_या</th>\n",
       "      <th>3_ د</th>\n",
       "      <th>4_行</th>\n",
       "      <th>5_》</th>\n",
       "      <th>6_こ</th>\n",
       "      <th>7_ng</th>\n",
       "      <th>8_े</th>\n",
       "      <th>9_अ</th>\n",
       "      <th>...</th>\n",
       "      <th>554_ட</th>\n",
       "      <th>555_்க</th>\n",
       "      <th>556_ा</th>\n",
       "      <th>557_서</th>\n",
       "      <th>558_을</th>\n",
       "      <th>559_த்</th>\n",
       "      <th>560_ु</th>\n",
       "      <th>561_t</th>\n",
       "      <th>562_も</th>\n",
       "      <th>563_ं</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chars</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0_ أ  1_ ہ  2_या  3_ د  4_行  5_》  6_こ  7_ng  8_े  9_अ  ...  554_ட  \\\n",
       "Chars     1     1     1     1    1    1    1     1    1    1  ...      1   \n",
       "\n",
       "       555_்க  556_ा   557_서   558_을   559_த்  560_ु  561_t  562_も  563_ं   \n",
       "Chars       1       1       1       1       1      1      1      1       1  \n",
       "\n",
       "[1 rows x 564 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4b7a028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "      <th>560</th>\n",
       "      <th>561</th>\n",
       "      <th>562</th>\n",
       "      <th>563</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chars</th>\n",
       "      <td>ed</td>\n",
       "      <td>た。</td>\n",
       "      <td>m</td>\n",
       "      <td>ی</td>\n",
       "      <td>nd</td>\n",
       "      <td>d</td>\n",
       "      <td>と</td>\n",
       "      <td>د</td>\n",
       "      <td>ار</td>\n",
       "      <td>和</td>\n",
       "      <td>...</td>\n",
       "      <td>ใ</td>\n",
       "      <td>ไ</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>่</td>\n",
       "      <td>क</td>\n",
       "      <td>อง</td>\n",
       "      <td>‌</td>\n",
       "      <td>有</td>\n",
       "      <td>و</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9    ... 554 555 556 557 558 559  \\\n",
       "Chars  ed  た。   m  ی   nd   d   と  د   ار   和  ...   ใ   ไ   h   d   ่   क   \n",
       "\n",
       "      560 561 562 563  \n",
       "Chars  อง   ‌   有   و  \n",
       "\n",
       "[1 rows x 564 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "27d9c02f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a2d7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
