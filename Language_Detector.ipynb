{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Kaggle Data\n",
    "The dataset acquired from [Kaggle](https://www.kaggle.com/code/martinkk5575/language-detection/data) contains words from several different languages. The noise contained in the dataset are duplicate words. To reduce this noise, the words will be broken down into single and double characters, then rated based on how often they show up in that respective language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21995</th>\n",
       "      <td>hors du terrain les années  et  sont des année...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21996</th>\n",
       "      <td>ใน พศ  หลักจากที่เสด็จประพาสแหลมมลายู ชวา อินเ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21997</th>\n",
       "      <td>con motivo de la celebración del septuagésimoq...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21998</th>\n",
       "      <td>年月，當時還只有歲的她在美國出道，以mai-k名義推出首張英文《baby i like》，由...</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21999</th>\n",
       "      <td>aprilie sonda spațială messenger a nasa și-a ...</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  language\n",
       "0      klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
       "1      sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
       "2      ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
       "3      விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
       "4      de spons behoort tot het geslacht haliclona en...     Dutch\n",
       "...                                                  ...       ...\n",
       "21995  hors du terrain les années  et  sont des année...    French\n",
       "21996  ใน พศ  หลักจากที่เสด็จประพาสแหลมมลายู ชวา อินเ...      Thai\n",
       "21997  con motivo de la celebración del septuagésimoq...   Spanish\n",
       "21998  年月，當時還只有歲的她在美國出道，以mai-k名義推出首張英文《baby i like》，由...   Chinese\n",
       "21999   aprilie sonda spațială messenger a nasa și-a ...  Romanian\n",
       "\n",
       "[22000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import data*\n",
    "fileName = \"dataset.csv\"\n",
    "data = pd.read_csv(fileName)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=data['Text'] # Feature matrix\n",
    "y=data['language'] # Label\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the languages into a DataFrame that we aren't modifying\n",
    "language_list = set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5207     สัมประสิทธิ์ฮอลล์ ฟิสิกส์ไฟฟ้า เกี่ยวกับสนามแม...\n",
       "4450     เกิดวันที่  พฤศจิกายน ภาคอะนิเมะ คดีฆาตกรรมบนจ...\n",
       "7033     i omgivningarna runt manigotagan river park re...\n",
       "487      நிஞ்சா ஹட்டோரி 忍者ハットリくん ninja hattori என்பது க...\n",
       "19537    эта страница деятельности м в ломоносова — ярк...\n",
       "                               ...                        \n",
       "11964    باباجان غفورف تاریخ‌دان و نویسندهٔ کتاب تاریخ ...\n",
       "21575    en  fue invitado por fernando ii para ocupar l...\n",
       "5390     doğu kanada atabasklarına geleneksel olarak dü...\n",
       "860      پژواک د يوې ځانگړې پروژې په توگه د اساسي قانون...\n",
       "15795    テンサイについては糖分を高度に精製する必要があることからサトウキビと同じような黒糖を作るのは...\n",
       "Name: Text, Length: 17600, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(dataframe, chars):\n",
    "    arr = dataframe.to_numpy()\n",
    "    new_arr = np.zeros((len(arr), len(chars)))\n",
    "    i=0\n",
    "    j=0\n",
    "    for text in arr:\n",
    "        sentence = text\n",
    "        j=0\n",
    "        for char in chars:\n",
    "            count = 0\n",
    "            for letter in sentence:\n",
    "                if letter == char:\n",
    "                    count = count + 1\n",
    "                fraction = count/len(sentence)\n",
    "            new_arr[i,j] = fraction\n",
    "            j = j + 1\n",
    "        \n",
    "        i = i + 1\n",
    "            \n",
    "    data_frame = pd.DataFrame(new_arr, columns = chars)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_2(dataframe, chars):\n",
    "    arr = dataframe.to_numpy()\n",
    "    new_arr = np.zeros((len(arr), len(chars)))\n",
    "    i=0\n",
    "    j=0\n",
    "    for text in arr:\n",
    "        sentence = text\n",
    "        count = 0.0\n",
    "        j = 0\n",
    "        for list in chars:\n",
    "            count = 0.0\n",
    "            for char in list:\n",
    "                for letter in sentence:\n",
    "                    if letter == char:\n",
    "                        count = count + 1.0\n",
    "            fraction = count/len(sentence)\n",
    "            new_arr[i,j] = fraction\n",
    "            j = j+1\n",
    "        i = i+1\n",
    "    \n",
    "    names = ['english', 'estonian', 'swedish', 'thai', 'tamil', 'dutch', 'japanese', 'turkish', 'latin', 'urdu',\n",
    "             'indonesian', 'portuguese', 'french', 'chinese', 'korean', 'hindi', 'spanish', 'pushto', 'persian',\n",
    "             'romanian', 'russian', 'arabic']\n",
    "    \n",
    "    data_frame = pd.DataFrame(new_arr, columns = names)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>estonian</th>\n",
       "      <th>swedish</th>\n",
       "      <th>thai</th>\n",
       "      <th>tamil</th>\n",
       "      <th>dutch</th>\n",
       "      <th>japanese</th>\n",
       "      <th>turkish</th>\n",
       "      <th>latin</th>\n",
       "      <th>urdu</th>\n",
       "      <th>...</th>\n",
       "      <th>french</th>\n",
       "      <th>chinese</th>\n",
       "      <th>korean</th>\n",
       "      <th>hindi</th>\n",
       "      <th>spanish</th>\n",
       "      <th>pushto</th>\n",
       "      <th>persian</th>\n",
       "      <th>romanian</th>\n",
       "      <th>russian</th>\n",
       "      <th>arabic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523622</td>\n",
       "      <td>0.263780</td>\n",
       "      <td>0.523622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.192913</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038062</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>0.031142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034602</td>\n",
       "      <td>0.038062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.031142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264471</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    english  estonian   swedish      thai     tamil     dutch  japanese  \\\n",
       "0  0.000000  0.000000  0.000000  0.118919  0.000000  0.000000       0.0   \n",
       "1  0.000000  0.000000  0.000000  0.157277  0.000000  0.000000       0.0   \n",
       "2  0.523622  0.263780  0.523622  0.000000  0.000000  0.523622       0.0   \n",
       "3  0.038062  0.013841  0.031142  0.000000  0.034602  0.038062       0.0   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000       0.0   \n",
       "\n",
       "    turkish     latin  urdu  ...  french  chinese  korean  hindi   spanish  \\\n",
       "0  0.000000  0.000000   0.0  ...     0.0      0.0     0.0    0.0  0.000000   \n",
       "1  0.000000  0.000000   0.0  ...     0.0      0.0     0.0    0.0  0.000000   \n",
       "2  0.192913  0.598425   0.0  ...     0.0      0.0     0.0    0.0  0.208661   \n",
       "3  0.006920  0.031142   0.0  ...     0.0      0.0     0.0    0.0  0.013841   \n",
       "4  0.000000  0.000000   0.0  ...     0.0      0.0     0.0    0.0  0.000000   \n",
       "\n",
       "   pushto  persian  romanian   russian  arabic  \n",
       "0     0.0      0.0       0.0  0.000000     0.0  \n",
       "1     0.0      0.0       0.0  0.000000     0.0  \n",
       "2     0.0      0.0       0.0  0.000000     0.0  \n",
       "3     0.0      0.0       0.0  0.000000     0.0  \n",
       "4     0.0      0.0       0.0  0.264471     0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chars = [['e', 't', 'a', 'i', 'o', 'n', 's', 'h', 'r'], ['a', 'e', 'i', 'ä', 'ö', 'õ', 'š', 'ü', 'ž'], \n",
    "             ['å', 'ä', 'ö', 'a', 'e', 't', 'n', 'r', 's', 'i'], ['ก', 'ข', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ฌ'],\n",
    "             ['அ', 'ஆ', 'இ', 'ஈ', 'உ', 'ஊ', 'எ', 'ஏ', 'ஐ', 'ஒ'], ['a', 'e', 'i', 'o', 'h', 'n', 'r', 't', 's'], \n",
    "             ['㍿', '㍐', 'ヿ', 'ヾ', 'ヽ', 'ー', '・', 'ヺ', 'ヹ', 'ヸ'], ['ç', 'ğ', 'ı', 'İ', 'î', 'ö', 'ş', 'ü', 'a', 'e'],\n",
    "             ['a', 'e', 'i', 'n', 'r', 's', 't', 'u', 'm', 'd'], ['چ', 'ح', 'خ', 'ش', 'ن', 'ٹ', 'ن', 'ث', 'گ', 'ج'],\n",
    "             ['a', 'A', 'i', 'n', 'r', 'm', 's', 't', 'u', 'g'], ['â', 'ê', 'ô', 'ã', 'õ', 'à', 'è', 'ì', 'ò', 'ù'],\n",
    "             ['ô', 'û', 'à', 'è', 'ì', 'ò', 'ù', 'ë', 'ï', 'ü'], ['主', '人', '公', '阿', '米', '尔', '一', '样', '都', '是'],\n",
    "             ['응','의','이','익','인','일','임','입','잉','잎'], ['ः', 'ऺ', 'ऻ', 'ा', 'ि', 'ी', 'ॎ', 'ई', 'उ', 'ऊ'], \n",
    "             ['á', 'é', 'í', 'ó', 'ú', 'ñ', 'ü', 't', 'e', 'i'], ['ت', 'ا', 'ې', 'ښ', 'ن', 'ر', 'ع', 'ط', 'ړ', 'س'],\n",
    "             ['ق', ' غ', 'ج', 'ت', ' ن ', 'ی', 'ل ', 'ظ', 'ص', 'ز'], ['ă', 'â', 'î', 'ș', 'ş', 'ț', 'ţ'], \n",
    "             ['б', 'в', 'г', 'д', 'ж', 'з', 'к', 'л', 'м', 'н'], ['م', 'ص', 'ظ', 'و', 'ر', 'م', 'ي', 'ج', 'ز', 'ق']]\n",
    "\n",
    "panda = X_train.head()\n",
    "some_data = feature_engineering_2(panda, new_chars)\n",
    "some_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.8252272727272727\n"
     ]
    }
   ],
   "source": [
    "X_train_2 = X_train.head(6000)\n",
    "X_train_2_eng = feature_engineering_2(X_train_2, new_chars)\n",
    "\n",
    "y_train_2 = y_train.head(6000)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf_2 = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "rnd_clf_2.fit(X_train_2_eng, y_train_2)\n",
    "\n",
    "X_test_2 = feature_engineering_2(X_test, new_chars)\n",
    "y_preds_2 = rnd_clf_2.predict(X_test_2)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_score_2 = accuracy_score(y_test, y_preds_2)\n",
    "\n",
    "print('Accuracy=%s' % (acc_score_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Test Model\n",
    "----\n",
    "This is a test model to experiment how to implement the finalized model onto the flask website (via pickle file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.8822727272727273\n"
     ]
    }
   ],
   "source": [
    "#characters for first model\n",
    "chars_2 = ['e', 't', 'ä', 'ö', 'a', 'n', 'ก', 'ข', 'ค', 'ฅ', 'ฆ', 'ง', 'அ', 'ஆ', 'இ', 'ஈ', 'உ', 'ஊ', \n",
    "         'o', 'r', 'ー', '日', 'あ', 'ぁ', 'ぇ', 'ç', 'ğ', 'ı', 'İ', 'î', 'ö', 'ş', 'i', 'u', 'چ', 'ح', 'خ', 'ش',\n",
    "         'â', 'ù', 'è', 's', 'î', 'ë', '胡', '童', '。', 'ᄁ', '알', '에', 'ᄃ', 'ऺ', 'त', 'ऻ', 'क', 'á', 'é', 'í', \n",
    "         'ó', 'ږ','ک', 'ﻑ', 'ی', 'م', 'ث', 'ţ', 'ă', 'ș', 'ş', 'б', 'в', 'г', 'д', 'ص', 'ف', 'ج', 'ر']\n",
    "\n",
    "X_train_2 = X_train.head(3000)\n",
    "model_one = feature_engineering(X_train_2, chars_2)\n",
    "model_one\n",
    "\n",
    "y_train_one = y_train.head(3000)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "rnd_clf.fit(model_one, y_train_one)\n",
    "\n",
    "X_test_1 = feature_engineering(X_test, chars_2)\n",
    "\n",
    "y_preds = rnd_clf.predict(X_test_1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_score = accuracy_score(y_test, y_preds)\n",
    "\n",
    "print('Accuracy=%s' % (acc_score))\n",
    "\n",
    "import pickle #ask about pickle\n",
    "\n",
    "saved_model = pickle.dumps(rnd_clf)\n",
    "\n",
    "rdf_from_pickle = pickle.loads(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5207     สัมประสิทธิ์ฮอลล์ ฟิสิกส์ไฟฟ้า เกี่ยวกับสนามแม...\n",
       "4450     เกิดวันที่  พฤศจิกายน ภาคอะนิเมะ คดีฆาตกรรมบนจ...\n",
       "7033     i omgivningarna runt manigotagan river park re...\n",
       "487      நிஞ்சா ஹட்டோரி 忍者ハットリくん ninja hattori என்பது க...\n",
       "19537    эта страница деятельности м в ломоносова — ярк...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panda = X_train.head()\n",
    "panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_22_features = ['e', 't', 'a', 'i', 'o', 'á', 'é', 'í']\n",
    "\n",
    "test_data = feature_engineering(panda, first_22_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e</th>\n",
       "      <th>t</th>\n",
       "      <th>a</th>\n",
       "      <th>i</th>\n",
       "      <th>o</th>\n",
       "      <th>á</th>\n",
       "      <th>é</th>\n",
       "      <th>í</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.106299</td>\n",
       "      <td>0.051181</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.051181</td>\n",
       "      <td>0.023622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          e         t         a         i         o    á    é    í\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0\n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0\n",
       "2  0.106299  0.051181  0.086614  0.051181  0.023622  0.0  0.0  0.0\n",
       "3  0.000000  0.006920  0.006920  0.006920  0.003460  0.0  0.0  0.0\n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Features: Most Used Characters\n",
    "To train the models to determine which language is being used by the user, we first need to know which characters are used in each language. The best approach for this is to used the dataset, _which is already using the characters from each language_, and find the **most used characters** in them.\n",
    "\n",
    "### Kaggle Resources\n",
    "----\n",
    "The following code is taken from the [Kaggle](https://www.kaggle.com/code/martinkk5575/language-detection/notebook) to understand how to process characters for each language. Kaggle uses the `CountVectorizor` Method from the `sklearn` module to tokenize the characters into readable 1's and 0's. Then, it counts how many times that character has been used in the sample data provided.\n",
    "\n",
    "This method reduces the necessity of locating alphabets for each language and creating custom functions to find the most used characters in the dataset.\n",
    " \n",
    "**To summarize Kaggle's findings: Languages based off the Latin Alphabet are easier to differentiate from each other in the data set while Languages with their own Alphabet, _like Chinese and Japanese_, can be differentiated by single characters alone.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code here fits and transforms the X_train and X_test data sets into readable 1's and 0's and counts the number of times a specific character shows up in the datasets.The `min_df` parameter tells `CountVectorizor` to save any characters that are used **at least 1% of the time** in the dataset.\n",
    "\n",
    "These matrices are saved as `X_top1Percent_train_raw` and `X_top1Percent_test_raw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a list of single and double characters from the top 1% of to be used as features\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "top1PrecentMixtureVectorizer = CountVectorizer(analyzer='char', ngram_range=(1,2), min_df=1e-2)\n",
    "\n",
    "X_top1Percent_train_raw = top1PrecentMixtureVectorizer.fit_transform(X_train)\n",
    "X_top1Percent_test_raw = top1PrecentMixtureVectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `train_lang_dict()` function takes in the raw vectorized X_train and y_train data sets and converts them into readable dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Command from Kaggle connects the character features to their specific language\n",
    "\n",
    "# Aggregate Unigrams per language\n",
    "def train_lang_dict(X_raw_counts, y_train):\n",
    "    lang_dict = {}\n",
    "    for i in range(len(y_train)):\n",
    "        lang = y_train[i]\n",
    "        v = np.array(X_raw_counts[i])\n",
    "        if not lang in lang_dict:\n",
    "            lang_dict[lang] = v\n",
    "        else:\n",
    "            lang_dict[lang] += v\n",
    "            \n",
    "    # to relative\n",
    "    for lang in lang_dict:\n",
    "        v = lang_dict[lang]\n",
    "        lang_dict[lang] = v / np.sum(v)\n",
    "        \n",
    "    return lang_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1PrecentMixtureVectorizer = CountVectorizer(analyzer='char', ngram_range=(1,2), min_df=1e-2, max_df=.9)\n",
    "\n",
    "X_top1Percent_train_raw = top1PrecentMixtureVectorizer.fit_transform(X_train)\n",
    "X_top1Percent_test_raw = top1PrecentMixtureVectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovanni/.local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>（</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3074</th>\n",
       "      <td>）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>）。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>，</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>：</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3078 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      \"\n",
       "1      -\n",
       "2      [\n",
       "3      a\n",
       "4      b\n",
       "...   ..\n",
       "3073   （\n",
       "3074   ）\n",
       "3075  ）。\n",
       "3076   ，\n",
       "3077   ：\n",
       "\n",
       "[3078 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_dict_top1Percent = train_lang_dict(X_top1Percent_train_raw.toarray(), y_train.values)\n",
    "\n",
    "top1PercentFeatures = top1PrecentMixtureVectorizer.get_feature_names()\n",
    "\n",
    "pd.DataFrame(top1PercentFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Thai': array([4.17770312e-04, 2.00271335e-04, 1.29207313e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Swedish': array([1.08294023e-04, 3.09720905e-04, 6.49764136e-06, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Tamil': array([8.97649203e-05, 2.33806304e-04, 1.67004503e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Russian': array([2.04983331e-05, 2.81386209e-04, 1.67713635e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Urdu': array([1.27741205e-04, 5.50608643e-05, 1.54170420e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Chinese': array([0.00013874, 0.00019077, 0.        , ..., 0.00079775, 0.06036852,\n",
       "        0.00202905]),\n",
       " 'Spanish': array([2.13374681e-04, 1.49362276e-04, 8.89061169e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'English': array([5.62921665e-04, 1.82022574e-04, 2.35955189e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Persian': array([1.39777544e-05, 1.08327597e-04, 1.04833158e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Pushto': array([6.86916121e-05, 5.13625918e-04, 7.80586501e-06, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Romanian': array([1.72941167e-04, 3.50049590e-04, 1.25017711e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Arabic': array([5.09491904e-04, 1.95421552e-04, 2.79173646e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Portugese': array([3.29991795e-04, 1.92643859e-04, 2.49723520e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Turkish': array([3.92358406e-04, 2.41309630e-04, 9.21029121e-06, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Estonian': array([4.32378665e-04, 1.20976414e-04, 2.46433436e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Hindi': array([2.04801733e-04, 2.22157812e-04, 2.42985107e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Dutch': array([1.53033246e-04, 9.58583252e-04, 8.28930085e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Latin': array([0.00024306, 0.0003125 , 0.00010634, ..., 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " 'French': array([2.46755604e-05, 3.10207046e-04, 1.76254003e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Korean': array([9.32727675e-04, 3.10909225e-04, 4.74268309e-05, ...,\n",
       "        0.00000000e+00, 2.63482394e-04, 3.68875352e-05]),\n",
       " 'Indonesian': array([2.60997864e-04, 1.54468124e-04, 2.48569394e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'Japanese': array([7.98427712e-05, 9.15120993e-04, 0.00000000e+00, ...,\n",
       "        6.75592679e-04, 2.45670065e-05, 2.76378823e-04])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_dict_top1Percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `getRelevantGramsPerLanguage()` function processes the dictionary and returns a dictionary with only the top 50 **most used** characters for **each** language. This number _can_ be changed by setting `top=x` when you call `getRelevantGramsPerLanguage()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelevantGramsPerLanguage(features, language_dict, languages, top=50):\n",
    "    relevantGramsPerLanguage = {}\n",
    "    for lang in languages:\n",
    "        chars = []\n",
    "        relevantGramsPerLanguage[lang] = chars\n",
    "        v = language_dict[lang]\n",
    "        sortIndex = (-v).argsort()[:top]\n",
    "        for i in range(len(sortIndex)):\n",
    "            chars.append(features[sortIndex[i]])\n",
    "    return relevantGramsPerLanguage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below Displays the top 8 and 10 Characters from each language in a DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tamil': ['்', 'க', 'ு', 'ி', 'த', '் ', 'ப', 'ம'],\n",
       " 'Russian': ['о', 'и', 'е', 'а', 'н', 'с', 'р', 'т'],\n",
       " 'Swedish': ['e', 'r', 'a', 'n', 't', 'i', 's', 'd'],\n",
       " 'Thai': ['า', 'น', 'ร', 'ก', 'อ', '่', 'เ', 'ง'],\n",
       " 'Latin': ['i', 'a', 'e', 't', 's', 'n', 'r', 'u'],\n",
       " 'Portugese': ['a', 'e', 'o', 's', 'i', 'r', 'd', 'n'],\n",
       " 'Pushto': ['و', 'ا', 'ه', 'ي', 'ه ', 'د', 'ر', 'ل'],\n",
       " 'Chinese': ['，', '的', '。', '年', '在', '、', '一', '中'],\n",
       " 'Korean': ['이', '의', '다', '의 ', '에', '는', '는 ', '하'],\n",
       " 'English': ['e', 'a', 't', 'i', 'o', 'n', 's', 'r'],\n",
       " 'Urdu': ['ا', 'ی', 'ر', 'و', 'ک', 'م', 'ن', 'ہ'],\n",
       " 'Dutch': ['e', 'n', 'a', 'i', 'r', 't', 'o', 'd'],\n",
       " 'Hindi': ['ा', 'क', 'र', '्', 'े', 'ि', 'स', ' क'],\n",
       " 'Persian': ['ا', 'ی', 'ر', 'د', 'ن', 'ه', 'و', 'م'],\n",
       " 'Arabic': ['ا', 'ل', 'ي', 'ال', 'م', 'و', ' ا', 'ن'],\n",
       " 'French': ['e', 'a', 'n', 's', 'i', 'r', 't', 'l'],\n",
       " 'Romanian': ['e', 'a', 'i', 'r', 'n', 't', 'u', 'l'],\n",
       " 'Turkish': ['a', 'e', 'i', 'n', 'r', 'l', 'ı', 'd'],\n",
       " 'Estonian': ['a', 'i', 'e', 's', 't', 'l', 'n', 'u'],\n",
       " 'Japanese': ['の', '、', 'に', 'た', 'る', '。', 'は', 'と'],\n",
       " 'Indonesian': ['a', 'n', 'e', 'i', 'r', 'u', 't', 's'],\n",
       " 'Spanish': ['e', 'a', 'o', 'n', 's', 'r', 'i', 'l']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top8PerLanguage_dict = getRelevantGramsPerLanguage(top1PercentFeatures, language_dict_top1Percent, language_list, top=8)\n",
    "top8PerLanguage_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tamil': ['்', 'க', 'ு', 'ி', 'த', '் ', 'ப', 'ம', 'ட', 'ர'],\n",
       " 'Russian': ['о', 'и', 'е', 'а', 'н', 'с', 'р', 'т', 'в', 'л'],\n",
       " 'Swedish': ['e', 'r', 'a', 'n', 't', 'i', 's', 'd', 'l', 'o'],\n",
       " 'Thai': ['า', 'น', 'ร', 'ก', 'อ', '่', 'เ', 'ง', 'ม', 'ั'],\n",
       " 'Latin': ['i', 'a', 'e', 't', 's', 'n', 'r', 'u', 'o', 'm'],\n",
       " 'Portugese': ['a', 'e', 'o', 's', 'i', 'r', 'd', 'n', 't', 'm'],\n",
       " 'Pushto': ['و', 'ا', 'ه', 'ي', 'ه ', 'د', 'ر', 'ل', 'ن', ' د'],\n",
       " 'Chinese': ['，', '的', '。', '年', '在', '、', '一', '中', 'a', 'e'],\n",
       " 'Korean': ['이', '의', '다', '의 ', '에', '는', '는 ', '하', '을', '을 '],\n",
       " 'English': ['e', 'a', 't', 'i', 'o', 'n', 's', 'r', 'h', 'l'],\n",
       " 'Urdu': ['ا', 'ی', 'ر', 'و', 'ک', 'م', 'ن', 'ہ', 'ے', 'ل'],\n",
       " 'Dutch': ['e', 'n', 'a', 'i', 'r', 't', 'o', 'd', 's', 'n '],\n",
       " 'Hindi': ['ा', 'क', 'र', '्', 'े', 'ि', 'स', ' क', 'न', 'त'],\n",
       " 'Persian': ['ا', 'ی', 'ر', 'د', 'ن', 'ه', 'و', 'م', 'ت', 'ب'],\n",
       " 'Arabic': ['ا', 'ل', 'ي', 'ال', 'م', 'و', ' ا', 'ن', 'ت', 'ر'],\n",
       " 'French': ['e', 'a', 'n', 's', 'i', 'r', 't', 'l', 'e ', 'u'],\n",
       " 'Romanian': ['e', 'a', 'i', 'r', 'n', 't', 'u', 'l', 'o', 'c'],\n",
       " 'Turkish': ['a', 'e', 'i', 'n', 'r', 'l', 'ı', 'd', 'k', 't'],\n",
       " 'Estonian': ['a', 'i', 'e', 's', 't', 'l', 'n', 'u', 'o', 'k'],\n",
       " 'Japanese': ['の', '、', 'に', 'た', 'る', '。', 'は', 'と', 'ー', 'を'],\n",
       " 'Indonesian': ['a', 'n', 'e', 'i', 'r', 'u', 't', 's', 'an', 'k'],\n",
       " 'Spanish': ['e', 'a', 'o', 'n', 's', 'r', 'i', 'l', 'd', 't']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10PerLanguage_dict = getRelevantGramsPerLanguage(top1PercentFeatures, language_dict_top1Percent, language_list, top=10)\n",
    "top10PerLanguage_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictToArray(dict, languages=language_list):\n",
    "    '''Converts a Language dictionary to an array and removes the duplicate values'''\n",
    "    char = []\n",
    "\n",
    "    for lang in languages:\n",
    "        arr = dict[lang]\n",
    "        char = char + arr\n",
    "    \n",
    "    dict_array = list(set(char))\n",
    "\n",
    "    return dict_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ி', 'に', 'ง', 'd', 'е', '्', 'н', '，', '는 ', 'о', 'ि', 'ہ', 'ा', '는', '்', 'ம', ' ا', '의 ', 'r', 'ن', 'ı', 'e', ' क', 'た', 'ال', 'l', 'ل', 'は', 'เ', 'n', 's', '在', '的', 'ก', '、', 'と', 'อ', '다', 'の', 'ی', 'स', 'ي', '年', 'u', '。', 'க', 'т', 'и', 'i', 'る', 'र', 'a', 'ه', 'क', 'ا', '่', '하', 'ک', 'ر', 'த', 't', 'ப', 'ه ', 'с', 'د', 'م', 'а', '이', 'ร', 'o', '中', 'و', 'า', '에', '의', 'ு', 'р', '一', '் ', 'น', 'े']\n",
      "Total Number of Characters: 81\n"
     ]
    }
   ],
   "source": [
    "dict8_array = dictToArray(top8PerLanguage_dict)\n",
    "\n",
    "print(dict8_array)\n",
    "print(\"Total Number of Characters:\", len(dict8_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ி', 'に', 'ง', 'd', 'е', '을 ', '्', 'н', '，', '는 ', 'о', 'न', 'ि', 'ہ', 'ม', 'ा', '는', '்', 'ம', ' ا', '의 ', 'r', 'ن', 'ı', 'в', 'e', 'n ', ' क', 'た', 'ب', 'ال', 'l', 'ل', 'は', 'เ', 'n', 's', '在', '的', 'ก', '、', 'h', 'と', 'อ', '다', 'c', 'ے', 'त', 'の', 'л', 'ட', 'ی', 'स', 'ー', 'ي', '年', 'u', '。', 'க', '을', 'т', 'и', 'i', 'る', 'र', 'an', 'a', 'e ', 'ت', 'ه', 'क', 'ا', '่', '하', 'ک', 'ر', 'த', 't', 'ப', 'ه ', 'с', 'د', 'م', 'ர', 'ั', 'm', 'を', ' د', 'k', 'а', '이', 'o', 'ร', '中', 'و', 'า', '에', '의', 'ு', 'р', '一', '் ', 'น', 'े']\n",
      "Total Number of Characters: 104\n"
     ]
    }
   ],
   "source": [
    "dict10_array = dictToArray(top10PerLanguage_dict)\n",
    "\n",
    "print(dict10_array)\n",
    "print(\"Total Number of Characters:\", len(dict10_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model (Uncleaned Data): RandomForests\n",
    "Now that we know the top 8 and 10 used characters for each language, we can use them to train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll use our `feature engineering` function to find the number of times our characters are used in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data for top 8 char usage\n",
    "dict8Frame = feature_engineering(X_train, dict8_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ி</th>\n",
       "      <th>に</th>\n",
       "      <th>ง</th>\n",
       "      <th>d</th>\n",
       "      <th>е</th>\n",
       "      <th>्</th>\n",
       "      <th>н</th>\n",
       "      <th>，</th>\n",
       "      <th>는</th>\n",
       "      <th>о</th>\n",
       "      <th>...</th>\n",
       "      <th>و</th>\n",
       "      <th>า</th>\n",
       "      <th>에</th>\n",
       "      <th>의</th>\n",
       "      <th>ு</th>\n",
       "      <th>р</th>\n",
       "      <th>一</th>\n",
       "      <th>்</th>\n",
       "      <th>น</th>\n",
       "      <th>े</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.035211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039370</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072664</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.07984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17595</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17596</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053812</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17597</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035354</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17598</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17599</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17600 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ி        に         ง         d        е    ्         н    ，  \\\n",
       "0      0.000000  0.00000  0.027027  0.000000  0.00000  0.0  0.000000  0.0   \n",
       "1      0.000000  0.00000  0.035211  0.000000  0.00000  0.0  0.000000  0.0   \n",
       "2      0.000000  0.00000  0.000000  0.039370  0.00000  0.0  0.000000  0.0   \n",
       "3      0.072664  0.00000  0.000000  0.000000  0.00000  0.0  0.000000  0.0   \n",
       "4      0.000000  0.00000  0.000000  0.000000  0.07984  0.0  0.063872  0.0   \n",
       "...         ...      ...       ...       ...      ...  ...       ...  ...   \n",
       "17595  0.000000  0.00000  0.000000  0.000000  0.00000  0.0  0.000000  0.0   \n",
       "17596  0.000000  0.00000  0.000000  0.053812  0.00000  0.0  0.000000  0.0   \n",
       "17597  0.000000  0.00000  0.000000  0.035354  0.00000  0.0  0.000000  0.0   \n",
       "17598  0.000000  0.00000  0.000000  0.000000  0.00000  0.0  0.000000  0.0   \n",
       "17599  0.000000  0.03268  0.000000  0.000000  0.00000  0.0  0.000000  0.0   \n",
       "\n",
       "        는          о  ...         و         า    에    의         ு         р  \\\n",
       "0      0.0  0.000000  ...  0.000000  0.064865  0.0  0.0  0.000000  0.000000   \n",
       "1      0.0  0.000000  ...  0.000000  0.051643  0.0  0.0  0.000000  0.000000   \n",
       "2      0.0  0.000000  ...  0.000000  0.000000  0.0  0.0  0.000000  0.000000   \n",
       "3      0.0  0.000000  ...  0.000000  0.000000  0.0  0.0  0.044983  0.000000   \n",
       "4      0.0  0.112774  ...  0.000000  0.000000  0.0  0.0  0.000000  0.042914   \n",
       "...    ...       ...  ...       ...       ...  ...  ...       ...       ...   \n",
       "17595  0.0  0.000000  ...  0.051195  0.000000  0.0  0.0  0.000000  0.000000   \n",
       "17596  0.0  0.000000  ...  0.000000  0.000000  0.0  0.0  0.000000  0.000000   \n",
       "17597  0.0  0.000000  ...  0.000000  0.000000  0.0  0.0  0.000000  0.000000   \n",
       "17598  0.0  0.000000  ...  0.061404  0.000000  0.0  0.0  0.000000  0.000000   \n",
       "17599  0.0  0.000000  ...  0.000000  0.000000  0.0  0.0  0.000000  0.000000   \n",
       "\n",
       "         一   ்          น    े  \n",
       "0      0.0  0.0  0.032432  0.0  \n",
       "1      0.0  0.0  0.056338  0.0  \n",
       "2      0.0  0.0  0.000000  0.0  \n",
       "3      0.0  0.0  0.000000  0.0  \n",
       "4      0.0  0.0  0.000000  0.0  \n",
       "...    ...  ...       ...  ...  \n",
       "17595  0.0  0.0  0.000000  0.0  \n",
       "17596  0.0  0.0  0.000000  0.0  \n",
       "17597  0.0  0.0  0.000000  0.0  \n",
       "17598  0.0  0.0  0.000000  0.0  \n",
       "17599  0.0  0.0  0.000000  0.0  \n",
       "\n",
       "[17600 rows x 81 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict8Frame # showcase training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a `RandomForestClassifier` model will be trained on the created data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_leaf_nodes=16, n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# instantiate a random forest clf \n",
    "rfc = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "\n",
    "# fit our ranom forest clf model onto our training data\n",
    "rfc.fit(dict8Frame, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set will be vectorized and predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the testing data\n",
    "testVectorizor = feature_engineering(X_test, dict8_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our predictions\n",
    "y_8pred = rfc.predict(testVectorizor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to display our accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of top 8 used characters: 0.8431818181818181\n",
      "Precision Score of top 8 used characters: 0.8431818181818181\n",
      "Recall Score of top 8 used characters: 0.8431818181818181\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# intantiate our clf performance metrics\n",
    "acc8 = accuracy_score(y_test, y_8pred) \n",
    "prec8 = precision_score(y_test, y_8pred, average='micro')\n",
    "rec8 = recall_score(y_test, y_8pred, average='micro')\n",
    "\n",
    "# showcase our scores\n",
    "print(\"Accuracy Score of top 8 used characters:\",acc8)\n",
    "print(\"Precision Score of top 8 used characters:\",prec8)\n",
    "print(\"Recall Score of top 8 used characters:\",rec8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the Top 10 Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the training data\n",
    "dict10Frame = feature_engineering(X_train, dict10_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ி</th>\n",
       "      <th>に</th>\n",
       "      <th>ง</th>\n",
       "      <th>d</th>\n",
       "      <th>е</th>\n",
       "      <th>을</th>\n",
       "      <th>्</th>\n",
       "      <th>н</th>\n",
       "      <th>，</th>\n",
       "      <th>는</th>\n",
       "      <th>...</th>\n",
       "      <th>و</th>\n",
       "      <th>า</th>\n",
       "      <th>에</th>\n",
       "      <th>의</th>\n",
       "      <th>ு</th>\n",
       "      <th>р</th>\n",
       "      <th>一</th>\n",
       "      <th>்</th>\n",
       "      <th>น</th>\n",
       "      <th>े</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.035211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039370</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072664</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.07984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17595</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17596</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053812</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17597</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035354</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17598</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17599</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17600 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ி        に         ง         d        е   을     ्         н  \\\n",
       "0      0.000000  0.00000  0.027027  0.000000  0.00000  0.0  0.0  0.000000   \n",
       "1      0.000000  0.00000  0.035211  0.000000  0.00000  0.0  0.0  0.000000   \n",
       "2      0.000000  0.00000  0.000000  0.039370  0.00000  0.0  0.0  0.000000   \n",
       "3      0.072664  0.00000  0.000000  0.000000  0.00000  0.0  0.0  0.000000   \n",
       "4      0.000000  0.00000  0.000000  0.000000  0.07984  0.0  0.0  0.063872   \n",
       "...         ...      ...       ...       ...      ...  ...  ...       ...   \n",
       "17595  0.000000  0.00000  0.000000  0.000000  0.00000  0.0  0.0  0.000000   \n",
       "17596  0.000000  0.00000  0.000000  0.053812  0.00000  0.0  0.0  0.000000   \n",
       "17597  0.000000  0.00000  0.000000  0.035354  0.00000  0.0  0.0  0.000000   \n",
       "17598  0.000000  0.00000  0.000000  0.000000  0.00000  0.0  0.0  0.000000   \n",
       "17599  0.000000  0.03268  0.000000  0.000000  0.00000  0.0  0.0  0.000000   \n",
       "\n",
       "         ，   는   ...         و         า    에    의         ு         р    一  \\\n",
       "0      0.0  0.0  ...  0.000000  0.064865  0.0  0.0  0.000000  0.000000  0.0   \n",
       "1      0.0  0.0  ...  0.000000  0.051643  0.0  0.0  0.000000  0.000000  0.0   \n",
       "2      0.0  0.0  ...  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.0   \n",
       "3      0.0  0.0  ...  0.000000  0.000000  0.0  0.0  0.044983  0.000000  0.0   \n",
       "4      0.0  0.0  ...  0.000000  0.000000  0.0  0.0  0.000000  0.042914  0.0   \n",
       "...    ...  ...  ...       ...       ...  ...  ...       ...       ...  ...   \n",
       "17595  0.0  0.0  ...  0.051195  0.000000  0.0  0.0  0.000000  0.000000  0.0   \n",
       "17596  0.0  0.0  ...  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.0   \n",
       "17597  0.0  0.0  ...  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.0   \n",
       "17598  0.0  0.0  ...  0.061404  0.000000  0.0  0.0  0.000000  0.000000  0.0   \n",
       "17599  0.0  0.0  ...  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.0   \n",
       "\n",
       "        ்          น    े  \n",
       "0      0.0  0.032432  0.0  \n",
       "1      0.0  0.056338  0.0  \n",
       "2      0.0  0.000000  0.0  \n",
       "3      0.0  0.000000  0.0  \n",
       "4      0.0  0.000000  0.0  \n",
       "...    ...       ...  ...  \n",
       "17595  0.0  0.000000  0.0  \n",
       "17596  0.0  0.000000  0.0  \n",
       "17597  0.0  0.000000  0.0  \n",
       "17598  0.0  0.000000  0.0  \n",
       "17599  0.0  0.000000  0.0  \n",
       "\n",
       "[17600 rows x 104 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict10Frame # showcase training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_leaf_nodes=16, n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate another random forest clf with same hyperparameters\n",
    "rfc2 = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "\n",
    "# fit our random forest clf model onto the training data \n",
    "rfc2.fit(dict10Frame, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the testing data\n",
    "test2Vectorizor = feature_engineering(X_test, dict10_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Japanese', 'Russian', 'Latin', ..., 'English', 'Persian', 'Dutch'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save our predictions \n",
    "y_10pred = rfc2.predict(test2Vectorizor)\n",
    "\n",
    "y_10pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of top 10 used characters: 0.8936363636363637\n",
      "Precision Score of top 10 used characters: 0.8936363636363637\n",
      "Recall Score of top 10 used characters: 0.8936363636363637\n"
     ]
    }
   ],
   "source": [
    "# instantiate clf performance metrics\n",
    "acc10 = accuracy_score(y_test, y_10pred)\n",
    "prec10 = precision_score(y_test, y_10pred, average='micro')\n",
    "rec10 = recall_score(y_test, y_10pred, average='micro')\n",
    "\n",
    "# showcase our scores\n",
    "print(\"Accuracy Score of top 10 used characters:\",acc10)\n",
    "print(\"Precision Score of top 10 used characters:\",prec10)\n",
    "print(\"Recall Score of top 10 used characters:\",rec10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model (Cleaned Data): RandomForests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let's Use Some Cleaned Data to see if our accuracy increases\n",
    "\n",
    "_A custom data cleaner program (Language_Detector_Cleaner) was used to removed duplicate words from the dataset. So, if an Enlgish word was in the Chinese or Japanese set of words, for example, it would be removed from that section. The Pushto language was removed as it was causing errors during the cleaning process_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>palsameeriti surnukeha hilja ning tundemärke ...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sebes joseph pereira thomas på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน เริ่มตั้งแต่ถนนสนามไช...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்தி...</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>de spons behoort tot het geslacht haliclona e...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20995</th>\n",
       "      <td>20995</td>\n",
       "      <td>hors du terrain les années et sont des années...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20996</th>\n",
       "      <td>20996</td>\n",
       "      <td>พศ หลักจากที่เสด็จประพาสแหลมมลายู ชวา อินเดีย...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20997</th>\n",
       "      <td>20997</td>\n",
       "      <td>con motivo de la celebración del septuagésimo...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>20998</td>\n",
       "      <td>年月，當時還只有歲的她在美國出道，以mai-k名義推出首張英文《baby after</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20999</th>\n",
       "      <td>20999</td>\n",
       "      <td>aprilie sonda spațială messenger a nasa și-a ...</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               Text  language\n",
       "0               0   palsameeriti surnukeha hilja ning tundemärke ...  Estonian\n",
       "1               1   sebes joseph pereira thomas på eng the jesuit...   Swedish\n",
       "2               2   ถนนเจริญกรุง อักษรโรมัน เริ่มตั้งแต่ถนนสนามไช...      Thai\n",
       "3               3   விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்தி...     Tamil\n",
       "4               4   de spons behoort tot het geslacht haliclona e...     Dutch\n",
       "...           ...                                                ...       ...\n",
       "20995       20995   hors du terrain les années et sont des années...    French\n",
       "20996       20996   พศ หลักจากที่เสด็จประพาสแหลมมลายู ชวา อินเดีย...      Thai\n",
       "20997       20997   con motivo de la celebración del septuagésimo...   Spanish\n",
       "20998       20998        年月，當時還只有歲的她在美國出道，以mai-k名義推出首張英文《baby after    Chinese\n",
       "20999       20999   aprilie sonda spațială messenger a nasa și-a ...  Romanian\n",
       "\n",
       "[21000 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in our Cleaned Data\n",
    "import pandas as pd\n",
    "data_clean = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "data_clean # showcase data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into Training and Testing Sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_clean = data_clean['Text'] # feature matrix (or feature vector -> 1 column)\n",
    "y_clean = data_clean['language'] # label\n",
    "\n",
    "# store our labels in memory\n",
    "language_list_clean = set(y_clean)\n",
    "\n",
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arabic',\n",
       " 'Chinese',\n",
       " 'Dutch',\n",
       " 'English',\n",
       " 'Estonian',\n",
       " 'French',\n",
       " 'Hindi',\n",
       " 'Indonesian',\n",
       " 'Japanese',\n",
       " 'Korean',\n",
       " 'Latin',\n",
       " 'Persian',\n",
       " 'Portugese',\n",
       " 'Romanian',\n",
       " 'Russian',\n",
       " 'Spanish',\n",
       " 'Swedish',\n",
       " 'Tamil',\n",
       " 'Thai',\n",
       " 'Turkish',\n",
       " 'Urdu'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_list_clean # showcase what are language labels actually are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Top 8 and 10 Char Dictionaries for Clean Data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "charVectorizor_clean = CountVectorizer(analyzer='char', ngram_range=(1,2), min_df=1e-2)\n",
    "\n",
    "X_train_clean_raw = charVectorizor_clean.fit_transform(X_train_clean)\n",
    "X_test_clean_raw = charVectorizor_clean.transform(X_test_clean)\n",
    "language_dict_clean = train_lang_dict(X_train_clean_raw.toarray(), y_train_clean.values)\n",
    "\n",
    "Features_clean = charVectorizor_clean.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "top8PerLanguage_dict_clean = getRelevantGramsPerLanguage(Features_clean, language_dict_clean, language_list_clean, top=8)\n",
    "top10PerLanguage_dict_clean = getRelevantGramsPerLanguage(Features_clean, language_dict_clean, language_list_clean, top=10)\n",
    "\n",
    "dict8_array_clean = dictToArray(top8PerLanguage_dict_clean, language_list_clean)\n",
    "dict10_array_clean = dictToArray(top10PerLanguage_dict_clean, language_list_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize Clean Data\n",
    "dict8Frame_clean = feature_engineering(X_train_clean, dict8_array_clean)\n",
    "dict10Frame_clean = feature_engineering(X_train_clean, dict10_array_clean)\n",
    "\n",
    "testVectorizor_clean = feature_engineering(X_test_clean, dict8_array_clean)\n",
    "test2Vectorizor_clean = feature_engineering(X_test_clean, dict10_array_clean)\n",
    "\n",
    "#Train Models for 8 and 10 Char\n",
    "\n",
    "# instantiate random forest clf with same hyperparameters\n",
    "rfc3 = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "# fit our random forest clf model onto our training data\n",
    "rfc3.fit(dict8Frame_clean, y_train_clean)\n",
    "\n",
    "# instantiate random forest clf with same hyperparameters\n",
    "rfc4 = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "# fit our random forest clf model onto our training data\n",
    "rfc4.fit(dict10Frame_clean, y_train_clean)\n",
    "\n",
    "#Make Predictions\n",
    "y_8pred_clean = rfc3.predict(testVectorizor_clean) # predictions regarding Top 8\n",
    "y_10pred_clean = rfc4.predict(test2Vectorizor_clean) # predictions regarding Top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for 8 Chars: 0.8088095238095238\n",
      "Precision Score for 8 Chars: 0.8088095238095238\n",
      "Recall Score for 8 Chars: 0.8088095238095238 \n",
      "\n",
      "Accuracy Score for 10 Chars: 0.8454761904761905\n",
      "Precision Score for 10 Chars: 0.8454761904761905\n",
      "Recall Score for 10 Chars: 0.8454761904761905\n"
     ]
    }
   ],
   "source": [
    "# Display Performance Scores\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# instantiate clf performance metrics for Top 8\n",
    "acc8_clean = accuracy_score(y_test_clean, y_8pred_clean)\n",
    "prec8_clean = precision_score(y_test_clean, y_8pred_clean, average='micro')\n",
    "rec8_clean = recall_score(y_test_clean, y_8pred_clean, average='micro')\n",
    "\n",
    "# instantiate clf performance metrics for Top 10\n",
    "acc10_clean = accuracy_score(y_test_clean, y_10pred_clean)\n",
    "prec10_clean = precision_score(y_test_clean, y_10pred_clean, average='micro')\n",
    "rec10_clean = recall_score(y_test_clean, y_10pred_clean, average='micro')\n",
    "\n",
    "# display scores for Top 8\n",
    "print(\"Accuracy Score for 8 Chars:\", acc8_clean)\n",
    "print(\"Precision Score for 8 Chars:\", prec8_clean)\n",
    "print(\"Recall Score for 8 Chars:\", rec8_clean, \"\\n\")\n",
    "\n",
    "# display scores for Top 10\n",
    "print(\"Accuracy Score for 10 Chars:\", acc10_clean)\n",
    "print(\"Precision Score for 10 Chars:\", prec10_clean)\n",
    "print(\"Recall Score for 10 Chars:\", rec10_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precentage Diffs:\n",
      " Accuracy 8 Char: -3.4372294372294387%\n",
      " Precision 8 Char: -3.4372294372294387%\n",
      " Recall 8 Char: -3.4372294372294387%\n",
      "Accuracy 10 Char: -4.816017316017318%\n",
      " Precision 10 Char: -4.816017316017318%\n",
      " Recall 10 Char: -4.816017316017318%\n"
     ]
    }
   ],
   "source": [
    "#Report Percentage Diff\n",
    "acc8_diff = (acc8_clean - acc8)*100\n",
    "prec8_diff = (prec8_clean - prec8)*100\n",
    "rec8_diff = (rec8_clean - rec8)*100\n",
    "\n",
    "acc10_diff = (acc10_clean - acc10)*100\n",
    "prec10_diff = (prec10_clean - prec10)*100\n",
    "rec10_diff = (rec10_clean - rec10)*100\n",
    "\n",
    "print(\"Precentage Diffs:\\n Accuracy 8 Char: {}%\\n Precision 8 Char: {}%\\n Recall 8 Char: {}%\\nAccuracy 10 Char: {}%\\n Precision 10 Char: {}%\\n Recall 10 Char: {}%\".format(acc8_diff, prec8_diff, rec8_diff, acc10_diff, prec10_diff, rec10_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6bf787",
   "metadata": {},
   "source": [
    "### Save the Model to Deploy\n",
    "----\n",
    "We are using the Joblib Module in Python to save our model. The reasoning behind this is because we are using NumPY arrays when processing our data. We will also need to save the dictionary that the model was trained on so we can vectorize user inputted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c660a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model = rfc2\n",
    "\n",
    "filename = \"test_model.pkl\"\n",
    "\n",
    "joblib.dump(model, filename)\n",
    "\n",
    "dictionary = dict10_array\n",
    "\n",
    "with open('model_dictionary', 'w', encoding='utf-8') as file:\n",
    "    for letter in dictionary:\n",
    "        file.write('{}\\n'.format(letter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb0d9c6",
   "metadata": {},
   "source": [
    "## Testing the Model with The Flask Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ecfd34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the quick brown fox jumps over the lazy dog\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ி</th>\n",
       "      <th>に</th>\n",
       "      <th>ง</th>\n",
       "      <th>d</th>\n",
       "      <th>е</th>\n",
       "      <th>을</th>\n",
       "      <th>्</th>\n",
       "      <th>н</th>\n",
       "      <th>，</th>\n",
       "      <th>는</th>\n",
       "      <th>...</th>\n",
       "      <th>و</th>\n",
       "      <th>า</th>\n",
       "      <th>에</th>\n",
       "      <th>의</th>\n",
       "      <th>ு</th>\n",
       "      <th>р</th>\n",
       "      <th>一</th>\n",
       "      <th>்</th>\n",
       "      <th>น</th>\n",
       "      <th>े</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ி    に    ง         d    е   을     ्    н    ，   는   ...    و    า    에  \\\n",
       "0   0.0  0.0  0.0  0.023256  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "6   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "7   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "8   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "9   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "10  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "11  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "12  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "13  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "14  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "15  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "16  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "17  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "18  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "19  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "20  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "21  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "22  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "23  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "24  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "25  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "26  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "27  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "28  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "29  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "30  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "31  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "32  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "33  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "34  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "35  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "36  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "37  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "38  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "39  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "40  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "41  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "42  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "      의    ு    р    一   ்     น    े  \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "11  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "13  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "14  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "15  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "16  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "17  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "18  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "19  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "20  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "21  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "22  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "23  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "24  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "25  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "26  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "27  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "28  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "29  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "30  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "31  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "32  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "33  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "34  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "35  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "36  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "37  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "38  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "39  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "40  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "41  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "42  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[43 rows x 104 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = open('model_dictionary', 'r', encoding='utf-8')\n",
    "text = \"the quick brown fox jumps over the lazy dog\"\n",
    "print(text)\n",
    "chars = dictionary.read().split('\\n')\n",
    "chars.pop()\n",
    "        \n",
    "new_arr = np.zeros((len(text), len(chars)))\n",
    "j=0\n",
    "for char in chars:\n",
    "    count = 0\n",
    "    for letter in text:\n",
    "        if letter == char:\n",
    "            count = count + 1\n",
    "        fraction = count/len(text)\n",
    "    new_arr[0,j] = fraction\n",
    "    j = j + 1\n",
    "\n",
    "data_frame = pd.DataFrame(new_arr, columns = chars)\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8f21d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "data = data_frame\n",
    "    \n",
    "#Grab a Pickle (Open PKL File)\n",
    "file = open('test_model.pkl', 'rb')\n",
    "\n",
    "#Eat the pickle (Load the Pickled Model)\n",
    "model = joblib.load(file)\n",
    "\n",
    "#See if you ate the right pickle (Predict)\n",
    "predicition = model.predict(data)\n",
    "\n",
    "predicition[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize to check for overfitting or underfitting\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create these arrays into dictonaries\n",
    "english_alpha = [a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z]\n",
    "estonian_alpha = [A, B, D, E, F, G, H, I, J, K, L, M, N, O, P, R, S, Š, Z, Ž, T, U, V, Õ, Ä, Ö, Ü]\n",
    "swedish_alpha = [a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z, å, ä, ö]\n",
    "thai_alpha = [ก, ข, ค, ฅ, ฆ, ง, จ, ฉ, ช, ฌ, ญ, ฎ, ฏ, ฐ, ฑ, ฒ, ณ, ด, ต, ถ, ท, ธ, น, บ, บ, ผ, ฝ, พ, ฟ, ภ, \n",
    "               ม, ย, ร, ล, ว, ศ, ษ, ส, ห, ฬ, อ, ฮ] \n",
    "tamil_alpha = [அ, ஆ, இ, ஈ, உ, ஊ, எ, ஏ, ஐ, ஒ, ஓ, ஔ, க, ங, ச, ஞ, ட, ண, த, ந, ன, ப, ம, ய, ர, ற, ல, ள, ழ, வ]\n",
    "dutch_alpha = english_alpha\n",
    "japanese_alpha = [ぁ, あ, ぃ, い, ぅ, う, ぇ, え, ぉ, お, か, が, き, ぎ, く, ぐ, け, げ, こ, ご, さ, ざ, し, じ, す, ず,\n",
    "                  せ, ぜ, そ, ぞ, た, だ, ち, ぢ, っ, つ, づ, て, で, と, ど, な, に, ぬ, ね, の, は, ば, ぱ, ひ, び, ぴ,\n",
    "                  ふ, ぶ, ぷ, へ, べ, れ, る, り, ら, よ, ょ, ゆ, ゅ, や, ゃ, も, め, む, み, ま, ぽ, ぼ, ほ, ぺ, ろ, ゎ,\n",
    "                  わ, ゐ, ゑ, を, ん, ゔ, ゕ, ゖ,  ゚, ゛, ゜, ゝ, ゞ, ゟ, ゠, ァ, ア, サ, ゴ, コ, ゲ, ケ, グ, ク, ギ, キ,\n",
    "                  ガ, カ, オ, ォ, エ, ェ, ウ, ゥ, イ, ィ, ザ, シ, ジ, ス, ズ, セ, ゼ, ソ, ゾ, タ ,ダ ,チ ,ヂ, ッ, ツ, ヅ,\n",
    "                  テ, デ, ト, ホ, ペ, ベ, ヘ, プ, ブ, フ, ピ, ビ, ヒ, パ, バ, ハ, ノ, ネ, ヌ, ニ, ナ, ド, ボ, ポ, マ, ミ, \n",
    "                  ム, メ, モ, ャ, ヤ, ュ, ユ, ョ, ヨ, ラ, リ, ル, レ, ロ, ヮ, ㍿, ㍐, ヿ, ヾ, ヽ, ー, ・, ヺ, ヹ, ヸ, ヷ,\n",
    "                  ヶ, ヵ, ヴ, ン, ヲ, ヱ, ヰ, ワ]\n",
    "turkish_alpha = [a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, r, s, t, u, v, y, z, ç, ğ, ı, İ, î, ö, ş, ü]\n",
    "latin_alpha = english_alpha\n",
    "urdu_alpha = [ش,س,ژ,ز,ڑ,ر,ذ,ڈ,د,خ,ح,چ,\n",
    "              ج,ث,ٹ,ت,پ,ب,آ,ا,ے,ی,ھ,ہ,و,ں,ن,م,ل,گ,ک,ق,ف,غ,ع,ظ,ط,ض,ص]\n",
    "indonesian_alpha = english_alpha\n",
    "portuguese_alpha = [ç, á, é, í, ó, ú, â, ê, ô, ã, õ, à, è, ì, ò, ù, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z]\n",
    "french_alpha = [ç, é, â, ê, î, ô, û, à, è, ì, ò, ù, ë, ï, ü, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z]\n",
    "chinese_alpha = [胡, 赛, 尼, 本, 人, 和, 小, 说, 的, 主, 人, 公, 阿, 米, 尔, 一, 样, 都, 是, 出, 生, 在, 阿, 富, 汗, 首, 都, \n",
    "                 喀, 布, 尔, 少, 年, 时, 代, 便, 离, 开, 了, 这, 个, 国, 家, 。, 胡, 赛, 尼, 直, 到, 年, 小, 说, 出, 版, 之, \n",
    "                 后, 才, 首, 次, 回, 到, 已, 经, 离, 开, 年, 的, 祖, 国, 。, 他, 在, 苏, 联, 入, 侵, 时, 离, 开, 了, 阿, 富, \n",
    "                 汗, 而, 他, 的, 很, 多, 童, 年, 好, 友, 在, 阿, 富, 汗, 生, 活, 在, 他, 们, 出, 发, 之, 前, 罗, 伯, 特, 伊,\n",
    "                 达, 尔, 文, 卷, 查, 尔, 斯, 赖, 尔, 所, 著, 地, 质, 学, 原, 理, 在, 南, 美, 他, 得, 到, 第, 卷, 该, 书, 将, \n",
    "                 地, 形, 地, 貌, 解, 释, 为, 漫, 长, 历, 史, 时, 间, 渐, 进, 演, 变, 的, 的, 结, 果, 当, 他, 旅, 程, 的, 第, \n",
    "                 站, 抵, 达, 圣, 地, 亚, 哥, 佛, 得, 角, 的, 时, 候, 达, 尔, 文]\n",
    "korean_alpha = [ᄁ,ᄂ,ᄃ,ᄄ,ᄅᄆᄇ,ᄈ,ᄉ,ᄊ,ᄋ,ᄌᄍ,ᄎ,ᄏ,ᄐ,ᄑᄒ,아,악,안,알,암,압,앙,앞애,액,앵야,얀,약,양,얘,어,억,\n",
    "                언,얼,엄,업,엉,에,여,역,연,열,염,엽,영,예,ᄀ,여,역,연,열,염,엽,영,예,오,옥,온,올,옴,옹,와,완,왈,왕,왜,외,왼,\n",
    "                요,욕,용,우,욱,운,울,움,웅,워,원,월,위,유,육,윤,율,융,윷,으,은,을,음읍,응,의,이,익,인,일,임,입,잉,잎]\n",
    "hindi_alpha = [ऄ, अ, आ, इ, ई, उ, ऊ, ऋ, ऌ, ऍ, ऎ, ए, ऐ, ऑ, ऒ, ओ, औ, क, ख, ग, घ, ङ, च, छ, ज, झ, प, ऩ, न, ध, द, \n",
    "               थ, त, ण, ढ, ड, ठ, ट, ञ, फ, ब, भ, म, य, र, ऱ, ल, ळ, ऴ, व, श, ष, ४, ३, २, १, ०, ॥, ।, ॡ, ॠ, ॐ, ऽ, \n",
    "               ह, स, ५, ६, ७, ॲ, ॳ, ॴ, ॵ, ॶ, ॷ, ॹ, ॺ, ॻ, ॼ, ॾ, ॿ, ೱऀँं, ः, ऺ, ऻ, ा, ि, ी, ॎ, ॏॕैेॣॢ, ॗ]\n",
    "spanish_alpha = [á, é, í, ó, ú, ñ, ü, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z]\n",
    "pushto_alpha = [,ﺏ ,پ ,ﺕ ,ټ ,ﺙ ,ﺝ ,چ ,ﺡ ,ﺥ ,څ ,ځ ,ﺩ ,ډ ,ﺫ ,ﺭ ,ړ ,ﺯ ,ژ ,ږ ,ﺱ ,ﺵ ,ښ ,ﺹ ,ﺽ ,ﻁ ,ﻅ ,ﻉ ,ﻍ ,ﻑ ,ﻕ ,ک ,ګ ,ﻝ ,ﻡ ,ﻥ ,ڼ, ,ﻭ ,ه ,ۀ ,ي ,ې ,ی ,ۍ ,ئ]\n",
    "persian_alpha = [,ش,س,ژ,ز,ر,ذ,د,خ,ح,چ,ج,ث,ت,پ,ب,آ,ا,ص,ض,ط,ظ,ع,غ,ف,ق,ک,گ,ل,م,ن,و,ه,ی]\n",
    "romanian_alpha = [ă, â, î, ș, ş, ț, ţ, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z]\n",
    "russian_alpha = [б, в, г, д, ж, з, к, л, м, н, п, р, с, т, ф, х, ц, ч, ш, щ, а, е, ё, и, о, у, ы, э, ю, я, й]\n",
    "arabic_alpha = [ش,س,ز,ر,ذ,د,خ,ح,ج,ث,ت,ب,ا,ء,ي,و,ه,ن,م,ل,ك,ق,ف,غ,ع,ظ,ط,ض,ص]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Average Word Length of a single string\n",
    "def avg_word_len(string):\n",
    "    # Split string up and find total amount of words present\n",
    "    words = string.split()\n",
    "    wordCount = len(words)\n",
    "    \n",
    "    # Calculate actual average  \n",
    "    ch = 0\n",
    "    for word in words:\n",
    "        ch += len(word) # Add up all chars\n",
    "    avg = ch / wordCount # Divide sum of chars by amount of words present\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the Average Sentence Length across a piece of text\n",
    "def avg_sent_len(text):\n",
    "  sentences = text.split(\".\") # Split the text into a list of sentences.\n",
    "  words = text.split(\" \") # split the input text into a list of separate words\n",
    "  if(sentences[len(sentences)-1]==\"\"): # if the last value in sentences is an empty string\n",
    "    average_sentence_length = len(words) / len(sentences)-1\n",
    "  else:\n",
    "    average_sentence_length = len(words) / len(sentences)\n",
    "  return average_sentence_length # returning avg length of sentence\n",
    "  \n",
    "ans = avg_sent_len(\"I am going.to see you later\") # function call\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets test this function (avg_sent_len)          #Mr., Dr., Ms., etc. are words that may be a problem for this function\n",
    "avg_sent_len(input(\"Provide a body of text: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "features = pd.get_dummies(data_trans)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3dc28c41b48d6c91098501e10eb7561a2dcc98b4d9118be61c148f3785c05de2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
